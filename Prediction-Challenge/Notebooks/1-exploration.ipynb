{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training = True\n",
    "nb_epoch = 960\n",
    "model_1 = True\n",
    "\n",
    "\n",
    "\n",
    "model_2 = not model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTS = False\n",
    "trade_plots = False \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = \"..\\Data\\X_train.csv\"\n",
    "y_train_path = \"..\\Data\\y_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv(x_train_path)\n",
    "# y_train = pd.read_csv(y_train_path)\n",
    "# y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data = 504 days × 24 stocks × 20 observations/day × 100 events/observation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a description of each column in the dataset. <br>\n",
    "\n",
    "| Column | Description |\n",
    "| ------ | ------------ |\n",
    "| **Obs_id** | which observation are we taking into account <br>-> for that observation we will keep track of the next 100 operations in the book orders |\n",
    "| **Venue_id** | for a given stock, exchanges can happen across many venues :  this id tracks which venue we consider <br> ==> it could be of importance (some stocks are typically traded across many venues ?) |\n",
    "| **order_id** | for a given observation sequence, each operation is related to an order. An order can be added, updated, deleted. <br>The order_id allows to track the lifecycle of individual orders within a sequence.   |\n",
    "| **action** |  A (adding an order to the book) , D (Deleting an order from the book), U = updating an action from the book |\n",
    "| **side** | B (bids, values to buy the action) , A (Ask, values to sell the action) \n",
    "| **Price** | - price : price of the order that was affected. *This best_bid_price , at the time of the first event, is substracted from all price reated columns (price, bid, ask  ) |\n",
    "| **bid , ask** |- bid , ask == best bid (highest bid) /best ask (lowest ask)   |\n",
    "| **bid_size, ask_size** |  volume of orders at the best bid, respectively ask, price  , on the *aggregated book* <br> => this too could be a valuable information, perhaps some stocks are encoutering more volume than others.  |\n",
    "|**flux** | the change in volume at a specific price level in the order book due to a particular event |\n",
    "|**Trade**|A boolean true or false to indicate whether a deletion or update event was due to a trade or due to a cancellation. <br> Most Deletions and updates actually dont occur from Trades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: For a given Observation\n",
    "\n",
    "| `order_id` | `action` | `price` | `side` | **Description**                                          |\n",
    "|------------|----------|---------|-------|----------------------------------------------------------|\n",
    "| 0          | A        | 100.5   | B     | A new order (ID 0) is added at 100.5 on the bid side.    |\n",
    "| 1          | A        | 101.0   | A     | A new order (ID 1) is added at 101.0 on the ask side.    |\n",
    "| 0          | U        | 100.5   | B     | The order with ID 0 is updated (e.g., quantity changed). |\n",
    "| 1          | D        | 101.0   | A     | The order with ID 1 is deleted (removed from the book).  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore trade info intuition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trade_plots:\n",
    "        \n",
    "    # Filter actions that are either 'D' or 'U'\n",
    "    du_actions = df[(df['action'].isin(['D', 'U']))]\n",
    "\n",
    "    # Count actions where 'trade' is True among 'D' or 'U'\n",
    "    du_trades = du_actions[du_actions['trade'] == True]\n",
    "\n",
    "    # Calculate the percentage\n",
    "    percentage = (len(du_trades) / len(du_actions)) * 100\n",
    "\n",
    "    # Display the result\n",
    "    print(f\"Percentage of 'D' or 'U' actions coming from trades: {percentage:.2f}%\")\n",
    "\n",
    "    # Merge the main DataFrame (df) with y_train using obs_id\n",
    "    df = df.merge(y_train, on='obs_id', how='left')  # Assuming y_train has columns ['obs_id', 'stock']\n",
    "\n",
    "    # Define a function to calculate the percentage for each observation\n",
    "    def calculate_percentage(sub_df):\n",
    "        is_du = sub_df['action'].isin(['D', 'U'])\n",
    "        is_du_trade = is_du & (sub_df['trade'] == True)\n",
    "        return (is_du_trade.sum() / is_du.sum()) * 100 if is_du.sum() > 0 else 0\n",
    "\n",
    "    # Group by obs_id and calculate percentage\n",
    "    df_obs = df.groupby('obs_id').apply(calculate_percentage).reset_index(name='percentage')\n",
    "\n",
    "    df_obs = df_obs.merge(y_train, on='obs_id', how='left')\n",
    "\n",
    "    # Group by stock and calculate statistics\n",
    "    stock_stats = df_obs.groupby('eqt_code_cat')['percentage'].agg(['mean', 'std', 'min', 'max'])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='eqt_code_cat', y='percentage', data=df_obs)\n",
    "    plt.title('Distribution of Percentages by Stock')\n",
    "    plt.xlabel('Stock')\n",
    "    plt.ylabel('Percentage of D/U Actions from Trades')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "    # Cap percentages at 6%\n",
    "    df_obs_capped = df_obs[df_obs['percentage'] <= 6]\n",
    "\n",
    "    # Create subplots: One histogram per stock\n",
    "    stocks = df_obs_capped['eqt_code_cat'].unique()  # Get unique stocks\n",
    "    num_stocks = len(stocks)\n",
    "\n",
    "    # Define the number of rows and columns for subplots\n",
    "    ncols = 4  # Number of columns\n",
    "    nrows = (num_stocks + ncols - 1) // ncols  # Calculate rows based on number of stocks\n",
    "\n",
    "    # Create the figure\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows * 3))\n",
    "    axes = axes.flatten()  # Flatten axes for easier indexing\n",
    "\n",
    "    # Plot each stock\n",
    "    for i, stock in enumerate(stocks):\n",
    "        # Filter the data for the current stock\n",
    "        stock_data = df_obs_capped[df_obs_capped['eqt_code_cat'] == stock]\n",
    "        \n",
    "        # Plot the histogram for the stock\n",
    "        sns.histplot(\n",
    "            stock_data,\n",
    "            x='percentage',\n",
    "            bins=30,\n",
    "            ax=axes[i],\n",
    "            element='step',\n",
    "            stat='percent'  # Show percentages instead of counts\n",
    "        )\n",
    "        axes[i].set_title(f'Stock {stock}', fontsize=12)\n",
    "        axes[i].set_xlim(0, 6)  # Cap the percentage at 6\n",
    "        axes[i].set_ylim(0, 100)  # Cap the y-axis at 100%\n",
    "        axes[i].set_xlabel('Percentage of D/U Actions', fontsize=10)\n",
    "        axes[i].set_ylabel('Percentage (%)', fontsize=10)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be three modes : 0% of trades , 2% of trades, 4% of trades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some ideas after the initial exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given observation, what can help determine the stock ?    \n",
    "we could use visualisation (for a given stock : average volatility observed , average number of increase of orders, average number of decrease of oders etc simple metrics as such)  \n",
    "  \n",
    "To go more in depth : we must use embeddings of our data, think of interesting traits, use correlations, try and reduce the dimensionality.  \n",
    "--> ideas seem endless we could train an embedding matrix to predict the venue idk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien d'actions d'affilée ? volatilité du prix sur les 100 actions ? prix max et min enregistrés ? % de trade ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volatilité : affichons la distribution de prix des variations de prix pour chacune des 24 actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv(x_train_path)\n",
    "# y_train = pd.read_csv(y_train_path)\n",
    "# y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def distrib_variations(data, stock ):\n",
    "#     # for a given sequence, we keep : lowest , highest (price)\n",
    "\n",
    "#     #une sequence est définie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing the Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark for the challenge is the following architecture :  \n",
    "\n",
    "Preprocess:  \n",
    "converting each event into a 30-dimensionnal vector.  \n",
    "group each 100-event-observations into a single \"observation\" vector, size 100x30\n",
    "  \n",
    "Architecture:  \n",
    "bidirectionnal GRU network, with 64 hidden units.  Producing a single 128 dimensional vector per \"observation vector\" .  \n",
    "Many to one architecture :converts the \"observation vector\" (of 100 individual events) into a single embedding of size 124.  \n",
    "Then two dense layers 124 -> 64 with SeLU activation, 64 -> 24 with softmax activation  \n",
    "  \n",
    "Training :  \n",
    "Cross entropy Loss  \n",
    "batch size : 1000 \"obervation vectors\"  (dim : 1000x100x30)  \n",
    "optimizer : Base ADAM with lr = 10e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing of the data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact pre process structure isnt described, so I will do what sounds relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a description of each column in the dataset. <br>\n",
    "\n",
    "| Column | Description |\n",
    "| ------ | ------------ |\n",
    "| **Obs_id** | which observation are we taking into account <br>-> for that observation we will keep track of the next 100 operations in the book orders |\n",
    "| **Venue_id** | for a given stock, exchanges can happen across many venues :  this id tracks which venue we consider <br> ==> it could be of importance (some stocks are typically traded across many venues ?) |\n",
    "| **order_id** | for a given observation sequence, each operation is related to an order. An order can be added, updated, deleted. <br>The order_id allows to track the lifecycle of individual orders within a sequence.   |\n",
    "| **action** |  A (adding an order to the book) , D (Deleting an order from the book), U = updating an action from the book |\n",
    "| **side** | B (bids, values to buy the action) , A (Ask, values to sell the action) \n",
    "| **Price** | - price : price of the order that was affected. *This best_bid_price , at the time of the first event, is substracted from all price reated columns (price, bid, ask  ) |\n",
    "| **bid , ask** |- bid , ask == best bid (highest bid) /best ask (lowest ask)   |\n",
    "| **bid_size, ask_size** |  volume of orders at the best bid, respectively ask, price  , on the *aggregated book* <br> => this too could be a valuable information, perhaps some stocks are encoutering more volume than others.  |\n",
    "|**flux** | the change in volume at a specific price level in the order book due to a particular event |\n",
    "|**Trade**|A boolean true or false to indicate whether a deletion or update event was due to a trade or due to a cancellation. <br> Most Deletions and updates actually dont occur from Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#venue => one hot encode it \n",
    "#action => one hot encode it \n",
    "#side : => one hot encode it \n",
    "#price,bid,ask,bid_size,ask_size,flux : no transfo\n",
    "#trade : one hot encode it \n",
    "\n",
    "#Justifications ? => none, just exploring \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import h5py  # For saving large arrays in memory-efficient HDF5 format\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(df_to_encode):\n",
    "    categorical_columns = ['venue','action','side','trade']\n",
    "    df_pandas_encoded = pd.get_dummies(df_to_encode,columns=categorical_columns,drop_first=True,dtype=int)\n",
    "\n",
    "    return df_pandas_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    #we want to drop obs_id, order_id \n",
    "    df = df.drop(['order_id','obs_id'],axis=1,errors='ignore') #dropping obs id because they did so in the benchmark\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_df(\n",
    "    df, \n",
    "    column_names=[\n",
    "        'price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux', \n",
    "        'venue_1', 'venue_2', 'venue_3', 'venue_4', 'venue_5', 'action_D', 'action_U', 'side_B',\n",
    "        'trade_True'\n",
    "    ]\n",
    "):\n",
    "    \"\"\"\n",
    "    Ensures the DataFrame has columns in a specified order, adding missing columns with zeros.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to correct.\n",
    "        column_names (list): List of column names in the desired order (default provided).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The corrected DataFrame.\n",
    "    \"\"\"\n",
    "    # Add missing columns with zeros\n",
    "    for column in column_names:\n",
    "        if column not in df.columns:\n",
    "            df[column] = 0\n",
    "    \n",
    "    # Reorder columns to match the specified order\n",
    "    df = df[column_names]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = x_train.head(int(10e3))\n",
    "# df_test = encode_df(df_test)\n",
    "# df_test = transform_df(df_test)\n",
    "# df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_data(data, k):\n",
    "    '''\n",
    "    input:\n",
    "        data - the pandas object of (n_observations x 100 , p) shape, where n is the number of rows,\n",
    "               p is the number of predictors\n",
    "        k    - the length of the sequences, namely, the number of previous rows \n",
    "               (including current) we want to use to predict the target.\n",
    "    output:\n",
    "        X_data - the predictors numpy matrix of (n-k, k, p) shape\n",
    "    '''\n",
    "\n",
    "\n",
    "    # initialize zero matrix of (n-k, k, p) shape to store the n-k number\n",
    "    # of sequences of k-length and zero array of (n-k, 1) to store targets\n",
    "    X_data = np.zeros((data.shape[0]//k, k, data.shape[1]))\n",
    "    \n",
    "    # run loop to slice k-number of previous rows as 1 sequence to predict\n",
    "    # 1 target and save them to X_data matrix and y_data list\n",
    "    for i in range(data.shape[0]//k):\n",
    "        cur_sequence = data.iloc[k*i: k*(i+1), :]\n",
    "                \n",
    "        X_data[i,:,:] = cur_sequence\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing a library to handle out-of-memeory packages https://stackoverflow.com/questions/30376581/save-numpy-array-in-append-mode/64403144#64403144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install npy-append-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npy_append_array import NpyAppendArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_data_chunked(x_train_path, y_train_path, output_prefix, chunk_size=10_000, seq_len=100):\n",
    "    \"\"\"\n",
    "    Process data chunk by chunk and save the results incrementally.\n",
    "    \n",
    "    Args:\n",
    "    - x_train_path: Path to the X_train CSV file.\n",
    "    - y_train_path: Path to the y_train CSV file.\n",
    "    - output_prefix: Prefix for the output files.\n",
    "    - chunk_size: Number of rows to process in each chunk.\n",
    "    - seq_len: Length of each sequence for LSTM.\n",
    "    \"\"\"\n",
    "    # Read y_train (the target file) entirely as it's small and doesn't need chunking\n",
    "    y_train_full = pd.read_csv(y_train_path).drop('obs_id', axis=1)\n",
    "\n",
    "    # Use tqdm to show progress\n",
    "    total_rows = sum(1 for _ in open(x_train_path)) - 1  # Get total rows excluding header\n",
    "    num_chunks = (total_rows + chunk_size - 1) // chunk_size  # Calculate total chunks\n",
    "\n",
    "    X_train_npy_name = f\"..\\Data\\{output_prefix}_X_train.npy\"\n",
    "    y_train_npy_name = f\"..\\Data\\{output_prefix}_y_train.npy\"\n",
    "\n",
    "\n",
    "    # Process the X_train file in chunks\n",
    "    with NpyAppendArray(X_train_npy_name, delete_if_exists=True) as npaa:\n",
    "        for i, chunk in enumerate(tqdm(pd.read_csv(x_train_path, chunksize=chunk_size), desc=\"Processing Chunks\", total=num_chunks)):\n",
    "            # Apply the transformation functions\n",
    "            chunk = correct_df(transform_df(encode_df(chunk)))\n",
    "\n",
    "            # Create LSTM-compatible data for this chunk\n",
    "            X_data = create_lstm_data(chunk, seq_len)\n",
    "\n",
    "            npaa.append(X_data)\n",
    "\n",
    "            # Clear memory for the current chunk\n",
    "            del X_data, chunk\n",
    "\n",
    "\n",
    "    np.save(y_train_npy_name,y_train_full)\n",
    "    print(f\"Processing completed. X_train and y_train saved as {output_prefix}_X_train.npy and {output_prefix}_y_train.npy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = '04-12'\n",
    "# process_data_chunked(x_train_path, y_train_path, date, chunk_size=10_000, seq_len=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = '05-12'\n",
    "# x_path_npy = fr'..\\Data\\{date}_X_train_LSTM.npy'\n",
    "# y_path_npy = fr'..\\Data\\{date}_y_train.npy'\n",
    "# # Load the .npy file\n",
    "# data = np.load(x_path_npy)\n",
    "\n",
    "# # Display the data (e.g., shape, a sample of the contents)\n",
    "# print(\"Data Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribs_vol_2 = [[] for k in range(24)]\n",
    "\n",
    "# for n in range(y_train.shape[0]):\n",
    "#     df_n = df.iloc[n*100:(n+1)*100,:]\n",
    "#     stock = df_n.iloc[0,:]['eqt_code_cat']\n",
    "#     max = df_n['price'].max()\n",
    "#     min = df_n['price'].min()\n",
    "\n",
    "#     distribs_vol_2[stock].append(max+min)\n",
    "    \n",
    "\n",
    "    \n",
    "# for i,stock in enumerate(distribs_vol_2):\n",
    "#     print(f'stock {i}, volatilité moyenne: {np.mean(stock)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# # Define the range and bin width\n",
    "\n",
    "# bin_width = 0.5\n",
    "# start = -300\n",
    "# end = 300\n",
    "\n",
    "# # Create bins\n",
    "# bins = np.arange(start, end + bin_width, bin_width)\n",
    "\n",
    "# def plot_volatilites(distribs):\n",
    "#     \"\"\"\n",
    "#     Affiche les distributions de volatilité sous forme d'histogrammes.\n",
    "\n",
    "#     Parameters:\n",
    "#     - distribs : list of arrays\n",
    "#         Chaque élément de la liste représente les volatilités pour un stock.\n",
    "#     \"\"\"\n",
    "#     num_stocks = len(distribs)\n",
    "#     plt.figure(figsize=(5, 5 * num_stocks))  # Ajustez la taille pour des visualisations claires\n",
    "    \n",
    "#     for i, stock_vol in enumerate(distribs):\n",
    "#         plt.subplot(num_stocks, 1, i + 1)  # Crée un subplot pour chaque stock\n",
    "#         plt.hist(stock_vol, bins=bins, edgecolor='black')  # Histogramme\n",
    "#         plt.title(f'Distribution des volatilités pour le stock {i}')\n",
    "#         plt.xlabel('Volatilité')\n",
    "#         plt.ylabel('Fréquence')\n",
    "#         plt.ylim(top=1000)\n",
    "#         plt.xlim([-300,300])\n",
    "    \n",
    "#     plt.tight_layout()  # Ajuste les espacements entre les subplots\n",
    "#     plt.show()\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # distribs_vol est supposé être une liste d'arrays de volatilités\n",
    "# plot_volatilites(distribs_vol_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# date = '05-12'\n",
    "\n",
    "# x_path_npy = fr'..\\Data\\{date}_X_train_add.npy'\n",
    "# y_path_npy = fr'..\\Data\\{date}_y_train.npy'\n",
    "\n",
    "# X_full = np.load(x_path_npy)#, mmap_mode=\"r\")\n",
    "# y_full = np.load(y_path_npy).ravel()#,mmap_mode=\"r\")\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=0)\n",
    "# gnb = GaussianNB()\n",
    "# y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "#       % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_path = r\"D:\\Desktop\\Coding-Projects\\Prediction-Challenge\\Notebooks\\27-11_y_train.npy\"\n",
    "# # Load the .npy file\n",
    "# y = np.load(y_path)\n",
    "\n",
    "# # Display the data (e.g., shape, a sample of the contents)\n",
    "# print(\"Data Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each sequence, We want to generate some value that seem interesting regarding the full sequence, such features could be generated by the LSTM but the search space is so big that we implement them by hannd\n",
    "\n",
    "# def genrate_additional_features(sequence: np.array)->np.array :\n",
    "#     '''\n",
    "#     given a sequence of 100x19 features \"sequence\" \n",
    "#     returns a np array \"features\" with relevant features '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import gc \n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs,x_path_npy,y_path_npy, batch_size=10050, dim=(100,15),\n",
    "                 n_classes=24, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.x_path = x_path_npy\n",
    "        self.y_path = y_path_npy\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        x_additional = np.empty((self.batch_size))\n",
    "        y = np.empty((self.batch_size))\n",
    "\n",
    "        # Generate data\n",
    "        X_full = np.load(self.x_path, mmap_mode=\"r\")\n",
    "        y_full = np.load(self.y_path,mmap_mode=\"r\")\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = X_full[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = y_full[ID].astype(int)[0]\n",
    "        \n",
    "        del X_full\n",
    "        del y_full\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Datasets\n",
    "# full_ids = np.arange(160800)\n",
    "\n",
    "# # Shuffle the IDs to ensure randomness\n",
    "# np.random.shuffle(full_ids)\n",
    "\n",
    "# # Compute the split index for 80/20\n",
    "# split_index = int(len(full_ids) * 13/16) #13/16 test, 3/16 val\n",
    "\n",
    "# # Split the IDs\n",
    "# train_ids = full_ids[:split_index]\n",
    "# val_ids = full_ids[split_index:]\n",
    "\n",
    "\n",
    "\n",
    "# # Define file paths\n",
    "# train_ids_path = \"train_ids.txt\"\n",
    "# val_ids_path = \"val_ids.txt\"\n",
    "\n",
    "# # Save the IDs to text files\n",
    "# with open(train_ids_path, \"w\") as train_file:\n",
    "#     for id in train_ids:\n",
    "#         train_file.write(f\"{id}\\n\")\n",
    "\n",
    "# with open(val_ids_path, \"w\") as val_file:\n",
    "#     for id in val_ids:\n",
    "#         val_file.write(f\"{id}\\n\")\n",
    "\n",
    "# print(\"Train and validation IDs saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation IDs loaded.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'dim': (100,15),\n",
    "          'batch_size': 10050,\n",
    "          'n_classes': 24,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "train_ids_path = \"train_ids.txt\"\n",
    "val_ids_path = \"val_ids.txt\"\n",
    "\n",
    "# Read the IDs from text files\n",
    "with open(train_ids_path, \"r\") as train_file:\n",
    "    train_ids = [int(line.strip()) for line in train_file]\n",
    "\n",
    "with open(val_ids_path, \"r\") as val_file:\n",
    "    val_ids = [int(line.strip()) for line in val_file]\n",
    "\n",
    "print(\"Train and validation IDs loaded.\")\n",
    "\n",
    "date = '05-12'\n",
    "x_path_npy = fr'..\\Data\\{date}_X_train_LSTM.npy'\n",
    "y_path_npy = fr'..\\Data\\{date}_y_train.npy'\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_ids,x_path_npy,y_path_npy, **params)\n",
    "val_generator = DataGenerator(val_ids,x_path_npy,y_path_npy, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data in a satisfactory format.  \n",
    "each row of our X_train is made of 100 event, each of these events is represented in a 18 dimension space.  \n",
    "and for each row of our train set, we have a single target value : in y  \n",
    "Let's now create a similar architecture as the benchmark  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Bidirectional,LSTM\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not resume_training:\n",
    "\n",
    "    if model_1:\n",
    "\n",
    "\n",
    "        # Input for fixed-length (length = 100) sequences of event observation (dimension = 19)\n",
    "        inputs = keras.Input(shape=(100,15))\n",
    "\n",
    "        # Add 2 bidirectional LSTMs\n",
    "        x = Bidirectional(LSTM(64))(inputs)\n",
    "        x = Dense(64)(x)\n",
    "\n",
    "        # Add a classifier\n",
    "        outputs = Dense(24, activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.summary()\n",
    "\n",
    "        \n",
    "    \n",
    "    if model_2:\n",
    "        \n",
    "\n",
    "        inputs = Input(shape=(100, 15))\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(inputs)\n",
    "        x = Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3))(x)\n",
    "        x = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        outputs = Dense(24, activation=\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=3e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "\n",
    "if model_2:\n",
    "    model_path = 'best_model2.h5'\n",
    "    csv_file = 'training_log_model2.csv'\n",
    "    mdl = 'model2'\n",
    "\n",
    "if model_1:\n",
    "    model_path = 'best_model.h5'\n",
    "    csv_file = 'training_log.csv'\n",
    "    mdl = 'model1'\n",
    "\n",
    "class SaveEveryNEpoch(Callback):\n",
    "    def __init__(self, save_path, n_epochs):\n",
    "        self.save_path = save_path\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.n_epochs == 0:\n",
    "            self.model.save(f\"{self.save_path}_epoch_{epoch + 1}.h5\")\n",
    "            print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "\n",
    "save_every_100_epochs = SaveEveryNEpoch(save_path=mdl+\"_checkpoint\", n_epochs=100)\n",
    "\n",
    "# Define callbacks to enhance and monitor the training process\n",
    "callbacks = [\n",
    "    # 1. ModelCheckpoint:\n",
    "    # Saves the model to a file ('best_model.h5') whenever the validation loss ('val_loss') improves.\n",
    "    # Ensures that only the best version of the model (with the lowest validation loss) is saved.\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,   # Filepath to save the model\n",
    "        monitor='val_loss',        # Metric to monitor\n",
    "        save_best_only=True,       # Save only the best model\n",
    "        mode='min'                 # Minimize the 'val_loss'\n",
    "    ),\n",
    "    \n",
    "    # 2. EarlyStopping:\n",
    "    # Stops training if the validation loss does not improve for 'patience' epochs (5 in this case).\n",
    "    # Prevents overfitting and saves time by stopping early when progress stalls.\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',        # Metric to monitor\n",
    "        patience=500,                # Number of epochs to wait without improvement\n",
    "        mode='min',                # Minimize the 'val_loss'\n",
    "        restore_best_weights=True  # Restore the model weights from the best epoch\n",
    "    ),\n",
    "    \n",
    "    # 3. ReduceLROnPlateau:\n",
    "    # Reduces the learning rate when the validation loss plateaus (does not improve for 3 epochs here).\n",
    "    # Helps the model converge better by lowering the learning rate when progress slows down.\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',        # Metric to monitor\n",
    "        factor=0.05,                # Factor by which to reduce the learning rate\n",
    "        patience=5,                # Number of epochs to wait before reducing the learning rate\n",
    "        min_lr=1e-6                # Minimum learning rate to avoid reducing it too much\n",
    "    ),\n",
    "    \n",
    "    # 4. TensorBoard:\n",
    "    # Logs training metrics, such as loss and accuracy, for visualization using TensorBoard.\n",
    "    # Also logs histograms and the computational graph of the model.\n",
    "    TensorBoard(\n",
    "        log_dir='./logs',          # Directory to save TensorBoard logs\n",
    "        histogram_freq=1,          # Log histograms of weights after every epoch\n",
    "        write_graph=True,          # Save the computation graph\n",
    "        write_images=True          # Save visualizations of weights and biases\n",
    "    ),\n",
    "    \n",
    "    # 5. CSVLogger:\n",
    "    # Logs training and validation metrics to a CSV file ('training_log.csv').\n",
    "    # Useful for tracking metrics over time and for external analysis.\n",
    "    CSVLogger(\n",
    "        filename=csv_file,  # Path to save the log file\n",
    "        append=True                  # Append to existing file if it exists\n",
    "    ),\n",
    "\n",
    "    # Save every 100 epochs\n",
    "    save_every_100_epochs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/960\n",
      "13/13 [==============================] - 181s 11s/step - loss: 2.5152 - accuracy: 0.1916 - val_loss: 2.5180 - val_accuracy: 0.1849 - lr: 0.0010\n",
      "Epoch 2/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.4507 - accuracy: 0.2051 - val_loss: 2.4683 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 3/960\n",
      "13/13 [==============================] - 139s 9s/step - loss: 2.4125 - accuracy: 0.2133 - val_loss: 2.4383 - val_accuracy: 0.2039 - lr: 0.0010\n",
      "Epoch 4/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.3889 - accuracy: 0.2193 - val_loss: 2.4297 - val_accuracy: 0.2060 - lr: 0.0010\n",
      "Epoch 5/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 2.3766 - accuracy: 0.2218 - val_loss: 2.4165 - val_accuracy: 0.2097 - lr: 0.0010\n",
      "Epoch 6/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 2.3685 - accuracy: 0.2246 - val_loss: 2.4021 - val_accuracy: 0.2146 - lr: 0.0010\n",
      "Epoch 7/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 2.3498 - accuracy: 0.2308 - val_loss: 2.3856 - val_accuracy: 0.2178 - lr: 0.0010\n",
      "Epoch 8/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 2.3476 - accuracy: 0.2311 - val_loss: 2.3816 - val_accuracy: 0.2186 - lr: 0.0010\n",
      "Epoch 9/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 2.3450 - accuracy: 0.2312 - val_loss: 2.3911 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 10/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 2.3279 - accuracy: 0.2357 - val_loss: 2.3716 - val_accuracy: 0.2237 - lr: 0.0010\n",
      "Epoch 11/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.3275 - accuracy: 0.2363 - val_loss: 2.3663 - val_accuracy: 0.2242 - lr: 0.0010\n",
      "Epoch 12/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.3065 - accuracy: 0.2418 - val_loss: 2.3586 - val_accuracy: 0.2275 - lr: 0.0010\n",
      "Epoch 13/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 2.3081 - accuracy: 0.2423 - val_loss: 2.3666 - val_accuracy: 0.2240 - lr: 0.0010\n",
      "Epoch 14/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.3050 - accuracy: 0.2428 - val_loss: 2.3451 - val_accuracy: 0.2273 - lr: 0.0010\n",
      "Epoch 15/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 2.2894 - accuracy: 0.2463 - val_loss: 2.3388 - val_accuracy: 0.2278 - lr: 0.0010\n",
      "Epoch 16/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 2.2782 - accuracy: 0.2496 - val_loss: 2.3424 - val_accuracy: 0.2323 - lr: 0.0010\n",
      "Epoch 17/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 2.2997 - accuracy: 0.2431 - val_loss: 2.3408 - val_accuracy: 0.2299 - lr: 0.0010\n",
      "Epoch 18/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 2.2744 - accuracy: 0.2513 - val_loss: 2.3185 - val_accuracy: 0.2361 - lr: 0.0010\n",
      "Epoch 19/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.2599 - accuracy: 0.2542 - val_loss: 2.3142 - val_accuracy: 0.2386 - lr: 0.0010\n",
      "Epoch 20/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.2749 - accuracy: 0.2493 - val_loss: 2.3110 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 21/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.2668 - accuracy: 0.2524 - val_loss: 2.3155 - val_accuracy: 0.2398 - lr: 0.0010\n",
      "Epoch 22/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 2.2502 - accuracy: 0.2574 - val_loss: 2.2983 - val_accuracy: 0.2439 - lr: 0.0010\n",
      "Epoch 23/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 2.2381 - accuracy: 0.2595 - val_loss: 2.2885 - val_accuracy: 0.2454 - lr: 0.0010\n",
      "Epoch 24/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 2.2318 - accuracy: 0.2622 - val_loss: 2.2880 - val_accuracy: 0.2443 - lr: 0.0010\n",
      "Epoch 25/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 2.2255 - accuracy: 0.2639 - val_loss: 2.2783 - val_accuracy: 0.2489 - lr: 0.0010\n",
      "Epoch 26/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.2585 - accuracy: 0.2565 - val_loss: 2.3035 - val_accuracy: 0.2438 - lr: 0.0010\n",
      "Epoch 27/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 2.2395 - accuracy: 0.2597 - val_loss: 2.2736 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 28/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.2201 - accuracy: 0.2652 - val_loss: 2.2656 - val_accuracy: 0.2534 - lr: 0.0010\n",
      "Epoch 29/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 2.2138 - accuracy: 0.2672 - val_loss: 2.2776 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 30/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.2160 - accuracy: 0.2664 - val_loss: 2.2918 - val_accuracy: 0.2478 - lr: 0.0010\n",
      "Epoch 31/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.2170 - accuracy: 0.2663 - val_loss: 2.2681 - val_accuracy: 0.2501 - lr: 0.0010\n",
      "Epoch 32/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 2.2104 - accuracy: 0.2697 - val_loss: 2.2517 - val_accuracy: 0.2548 - lr: 0.0010\n",
      "Epoch 33/960\n",
      "13/13 [==============================] - 135s 11s/step - loss: 2.1969 - accuracy: 0.2721 - val_loss: 2.2667 - val_accuracy: 0.2472 - lr: 0.0010\n",
      "Epoch 34/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 2.2196 - accuracy: 0.2663 - val_loss: 2.2571 - val_accuracy: 0.2563 - lr: 0.0010\n",
      "Epoch 35/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.1936 - accuracy: 0.2749 - val_loss: 2.2385 - val_accuracy: 0.2601 - lr: 0.0010\n",
      "Epoch 36/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 2.1709 - accuracy: 0.2790 - val_loss: 2.2295 - val_accuracy: 0.2627 - lr: 0.0010\n",
      "Epoch 37/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.1684 - accuracy: 0.2804 - val_loss: 2.2496 - val_accuracy: 0.2603 - lr: 0.0010\n",
      "Epoch 38/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 2.1724 - accuracy: 0.2792 - val_loss: 2.2398 - val_accuracy: 0.2577 - lr: 0.0010\n",
      "Epoch 39/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.1800 - accuracy: 0.2783 - val_loss: 2.2611 - val_accuracy: 0.2556 - lr: 0.0010\n",
      "Epoch 40/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 2.1721 - accuracy: 0.2798 - val_loss: 2.2271 - val_accuracy: 0.2650 - lr: 0.0010\n",
      "Epoch 41/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 2.1562 - accuracy: 0.2836 - val_loss: 2.2162 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 42/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 2.1490 - accuracy: 0.2841 - val_loss: 2.2170 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 43/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 2.1551 - accuracy: 0.2853 - val_loss: 2.2405 - val_accuracy: 0.2654 - lr: 0.0010\n",
      "Epoch 44/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.1524 - accuracy: 0.2848 - val_loss: 2.2334 - val_accuracy: 0.2650 - lr: 0.0010\n",
      "Epoch 45/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 2.1475 - accuracy: 0.2863 - val_loss: 2.2132 - val_accuracy: 0.2640 - lr: 0.0010\n",
      "Epoch 46/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.1314 - accuracy: 0.2905 - val_loss: 2.1955 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 47/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 2.1565 - accuracy: 0.2848 - val_loss: 2.2336 - val_accuracy: 0.2685 - lr: 0.0010\n",
      "Epoch 48/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.1455 - accuracy: 0.2877 - val_loss: 2.2054 - val_accuracy: 0.2728 - lr: 0.0010\n",
      "Epoch 49/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 2.1299 - accuracy: 0.2908 - val_loss: 2.1997 - val_accuracy: 0.2729 - lr: 0.0010\n",
      "Epoch 50/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 2.1389 - accuracy: 0.2911 - val_loss: 2.2218 - val_accuracy: 0.2673 - lr: 0.0010\n",
      "Epoch 51/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.1340 - accuracy: 0.2915 - val_loss: 2.1887 - val_accuracy: 0.2755 - lr: 0.0010\n",
      "Epoch 52/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 2.1241 - accuracy: 0.2927 - val_loss: 2.1867 - val_accuracy: 0.2787 - lr: 0.0010\n",
      "Epoch 53/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 2.1163 - accuracy: 0.2962 - val_loss: 2.1955 - val_accuracy: 0.2746 - lr: 0.0010\n",
      "Epoch 54/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.1089 - accuracy: 0.2982 - val_loss: 2.1752 - val_accuracy: 0.2776 - lr: 0.0010\n",
      "Epoch 55/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 2.1240 - accuracy: 0.2940 - val_loss: 2.1890 - val_accuracy: 0.2744 - lr: 0.0010\n",
      "Epoch 56/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 2.1149 - accuracy: 0.2954 - val_loss: 2.1705 - val_accuracy: 0.2807 - lr: 0.0010\n",
      "Epoch 57/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 2.0986 - accuracy: 0.3006 - val_loss: 2.1757 - val_accuracy: 0.2760 - lr: 0.0010\n",
      "Epoch 58/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 2.1112 - accuracy: 0.2977 - val_loss: 2.2011 - val_accuracy: 0.2752 - lr: 0.0010\n",
      "Epoch 59/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 2.1054 - accuracy: 0.2976 - val_loss: 2.1755 - val_accuracy: 0.2760 - lr: 0.0010\n",
      "Epoch 60/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 2.0866 - accuracy: 0.3035 - val_loss: 2.1606 - val_accuracy: 0.2840 - lr: 0.0010\n",
      "Epoch 61/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 2.0964 - accuracy: 0.3016 - val_loss: 2.1845 - val_accuracy: 0.2786 - lr: 0.0010\n",
      "Epoch 62/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 2.0903 - accuracy: 0.3023 - val_loss: 2.1603 - val_accuracy: 0.2844 - lr: 0.0010\n",
      "Epoch 63/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 2.0962 - accuracy: 0.3022 - val_loss: 2.1732 - val_accuracy: 0.2789 - lr: 0.0010\n",
      "Epoch 64/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 2.0961 - accuracy: 0.3026 - val_loss: 2.1760 - val_accuracy: 0.2807 - lr: 0.0010\n",
      "Epoch 65/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.0748 - accuracy: 0.3076 - val_loss: 2.1463 - val_accuracy: 0.2868 - lr: 0.0010\n",
      "Epoch 66/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.0799 - accuracy: 0.3077 - val_loss: 2.2220 - val_accuracy: 0.2717 - lr: 0.0010\n",
      "Epoch 67/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.1106 - accuracy: 0.2975 - val_loss: 2.1597 - val_accuracy: 0.2813 - lr: 0.0010\n",
      "Epoch 68/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 2.0820 - accuracy: 0.3054 - val_loss: 2.1467 - val_accuracy: 0.2871 - lr: 0.0010\n",
      "Epoch 69/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.0621 - accuracy: 0.3117 - val_loss: 2.1443 - val_accuracy: 0.2867 - lr: 0.0010\n",
      "Epoch 70/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.0761 - accuracy: 0.3104 - val_loss: 2.2923 - val_accuracy: 0.2618 - lr: 0.0010\n",
      "Epoch 71/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 2.1348 - accuracy: 0.2945 - val_loss: 2.1800 - val_accuracy: 0.2747 - lr: 0.0010\n",
      "Epoch 72/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.0799 - accuracy: 0.3057 - val_loss: 2.1449 - val_accuracy: 0.2898 - lr: 0.0010\n",
      "Epoch 73/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 2.0547 - accuracy: 0.3145 - val_loss: 2.1441 - val_accuracy: 0.2899 - lr: 0.0010\n",
      "Epoch 74/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 2.0733 - accuracy: 0.3102 - val_loss: 2.1745 - val_accuracy: 0.2804 - lr: 0.0010\n",
      "Epoch 75/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 2.0706 - accuracy: 0.3086 - val_loss: 2.1287 - val_accuracy: 0.2912 - lr: 0.0010\n",
      "Epoch 76/960\n",
      "13/13 [==============================] - 112s 9s/step - loss: 2.0481 - accuracy: 0.3173 - val_loss: 2.1311 - val_accuracy: 0.2938 - lr: 0.0010\n",
      "Epoch 77/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 2.0489 - accuracy: 0.3156 - val_loss: 2.1472 - val_accuracy: 0.2912 - lr: 0.0010\n",
      "Epoch 78/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.0500 - accuracy: 0.3172 - val_loss: 2.1462 - val_accuracy: 0.2862 - lr: 0.0010\n",
      "Epoch 79/960\n",
      "13/13 [==============================] - 131s 9s/step - loss: 2.0395 - accuracy: 0.3192 - val_loss: 2.1111 - val_accuracy: 0.2966 - lr: 0.0010\n",
      "Epoch 80/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 2.0238 - accuracy: 0.3237 - val_loss: 2.2212 - val_accuracy: 0.2796 - lr: 0.0010\n",
      "Epoch 81/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.0712 - accuracy: 0.3096 - val_loss: 2.1181 - val_accuracy: 0.2950 - lr: 0.0010\n",
      "Epoch 82/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.0383 - accuracy: 0.3192 - val_loss: 2.1112 - val_accuracy: 0.2994 - lr: 0.0010\n",
      "Epoch 83/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.0353 - accuracy: 0.3215 - val_loss: 2.1102 - val_accuracy: 0.2974 - lr: 0.0010\n",
      "Epoch 84/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 2.0398 - accuracy: 0.3193 - val_loss: 2.1176 - val_accuracy: 0.2989 - lr: 0.0010\n",
      "Epoch 85/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.0388 - accuracy: 0.3208 - val_loss: 2.1275 - val_accuracy: 0.2978 - lr: 0.0010\n",
      "Epoch 86/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 2.0188 - accuracy: 0.3246 - val_loss: 2.0994 - val_accuracy: 0.3025 - lr: 0.0010\n",
      "Epoch 87/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 2.0309 - accuracy: 0.3240 - val_loss: 2.1354 - val_accuracy: 0.2930 - lr: 0.0010\n",
      "Epoch 88/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 2.0117 - accuracy: 0.3272 - val_loss: 2.0897 - val_accuracy: 0.3051 - lr: 0.0010\n",
      "Epoch 89/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.9918 - accuracy: 0.3328 - val_loss: 2.0925 - val_accuracy: 0.3059 - lr: 0.0010\n",
      "Epoch 90/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.9978 - accuracy: 0.3309 - val_loss: 2.1594 - val_accuracy: 0.2933 - lr: 0.0010\n",
      "Epoch 91/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 2.0713 - accuracy: 0.3155 - val_loss: 2.1270 - val_accuracy: 0.2958 - lr: 0.0010\n",
      "Epoch 92/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 2.0234 - accuracy: 0.3253 - val_loss: 2.0984 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 93/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 2.0038 - accuracy: 0.3297 - val_loss: 2.0838 - val_accuracy: 0.3056 - lr: 0.0010\n",
      "Epoch 94/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 2.0007 - accuracy: 0.3309 - val_loss: 2.0973 - val_accuracy: 0.3057 - lr: 0.0010\n",
      "Epoch 95/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 2.0095 - accuracy: 0.3289 - val_loss: 2.0737 - val_accuracy: 0.3092 - lr: 0.0010\n",
      "Epoch 96/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.9904 - accuracy: 0.3343 - val_loss: 2.0813 - val_accuracy: 0.3083 - lr: 0.0010\n",
      "Epoch 97/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9822 - accuracy: 0.3373 - val_loss: 2.0655 - val_accuracy: 0.3102 - lr: 0.0010\n",
      "Epoch 98/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9687 - accuracy: 0.3393 - val_loss: 2.0605 - val_accuracy: 0.3128 - lr: 0.0010\n",
      "Epoch 99/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.9743 - accuracy: 0.3398 - val_loss: 2.0975 - val_accuracy: 0.3030 - lr: 0.0010\n",
      "Epoch 100/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.9947 - accuracy: 0.3353Model saved at epoch 100\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9947 - accuracy: 0.3353 - val_loss: 2.0707 - val_accuracy: 0.3096 - lr: 0.0010\n",
      "Epoch 101/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.9717 - accuracy: 0.3401 - val_loss: 2.0591 - val_accuracy: 0.3120 - lr: 0.0010\n",
      "Epoch 102/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.9790 - accuracy: 0.3382 - val_loss: 2.1300 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 103/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9908 - accuracy: 0.3351 - val_loss: 2.0868 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 104/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.9682 - accuracy: 0.3409 - val_loss: 2.0503 - val_accuracy: 0.3127 - lr: 0.0010\n",
      "Epoch 105/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.9527 - accuracy: 0.3459 - val_loss: 2.0449 - val_accuracy: 0.3175 - lr: 0.0010\n",
      "Epoch 106/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.9465 - accuracy: 0.3462 - val_loss: 2.0425 - val_accuracy: 0.3183 - lr: 0.0010\n",
      "Epoch 107/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.9441 - accuracy: 0.3474 - val_loss: 2.0504 - val_accuracy: 0.3168 - lr: 0.0010\n",
      "Epoch 108/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.9466 - accuracy: 0.3473 - val_loss: 2.0502 - val_accuracy: 0.3148 - lr: 0.0010\n",
      "Epoch 109/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 2.0311 - accuracy: 0.3264 - val_loss: 2.1151 - val_accuracy: 0.2996 - lr: 0.0010\n",
      "Epoch 110/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 2.0094 - accuracy: 0.3284 - val_loss: 2.0661 - val_accuracy: 0.3114 - lr: 0.0010\n",
      "Epoch 111/960\n",
      "13/13 [==============================] - 111s 9s/step - loss: 1.9661 - accuracy: 0.3416 - val_loss: 2.0677 - val_accuracy: 0.3096 - lr: 0.0010\n",
      "Epoch 112/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.9451 - accuracy: 0.3466 - val_loss: 2.0363 - val_accuracy: 0.3193 - lr: 5.0000e-05\n",
      "Epoch 113/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.9315 - accuracy: 0.3526 - val_loss: 2.0333 - val_accuracy: 0.3202 - lr: 5.0000e-05\n",
      "Epoch 114/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.9279 - accuracy: 0.3541 - val_loss: 2.0298 - val_accuracy: 0.3215 - lr: 5.0000e-05\n",
      "Epoch 115/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.9250 - accuracy: 0.3553 - val_loss: 2.0285 - val_accuracy: 0.3225 - lr: 5.0000e-05\n",
      "Epoch 116/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.9237 - accuracy: 0.3554 - val_loss: 2.0278 - val_accuracy: 0.3224 - lr: 5.0000e-05\n",
      "Epoch 117/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.9228 - accuracy: 0.3562 - val_loss: 2.0273 - val_accuracy: 0.3220 - lr: 5.0000e-05\n",
      "Epoch 118/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.9220 - accuracy: 0.3559 - val_loss: 2.0266 - val_accuracy: 0.3216 - lr: 5.0000e-05\n",
      "Epoch 119/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9213 - accuracy: 0.3561 - val_loss: 2.0262 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
      "Epoch 120/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.9205 - accuracy: 0.3561 - val_loss: 2.0257 - val_accuracy: 0.3229 - lr: 5.0000e-05\n",
      "Epoch 121/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.9200 - accuracy: 0.3560 - val_loss: 2.0255 - val_accuracy: 0.3217 - lr: 5.0000e-05\n",
      "Epoch 122/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.9196 - accuracy: 0.3562 - val_loss: 2.0250 - val_accuracy: 0.3220 - lr: 5.0000e-05\n",
      "Epoch 123/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9189 - accuracy: 0.3562 - val_loss: 2.0251 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
      "Epoch 124/960\n",
      "13/13 [==============================] - 127s 9s/step - loss: 1.9185 - accuracy: 0.3569 - val_loss: 2.0242 - val_accuracy: 0.3228 - lr: 5.0000e-05\n",
      "Epoch 125/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.9179 - accuracy: 0.3567 - val_loss: 2.0237 - val_accuracy: 0.3226 - lr: 5.0000e-05\n",
      "Epoch 126/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9174 - accuracy: 0.3568 - val_loss: 2.0236 - val_accuracy: 0.3227 - lr: 5.0000e-05\n",
      "Epoch 127/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.9170 - accuracy: 0.3572 - val_loss: 2.0231 - val_accuracy: 0.3225 - lr: 5.0000e-05\n",
      "Epoch 128/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9167 - accuracy: 0.3572 - val_loss: 2.0226 - val_accuracy: 0.3231 - lr: 5.0000e-05\n",
      "Epoch 129/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.9162 - accuracy: 0.3568 - val_loss: 2.0224 - val_accuracy: 0.3228 - lr: 5.0000e-05\n",
      "Epoch 130/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.9157 - accuracy: 0.3571 - val_loss: 2.0221 - val_accuracy: 0.3233 - lr: 5.0000e-05\n",
      "Epoch 131/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.9154 - accuracy: 0.3575 - val_loss: 2.0219 - val_accuracy: 0.3237 - lr: 5.0000e-05\n",
      "Epoch 132/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.9150 - accuracy: 0.3576 - val_loss: 2.0215 - val_accuracy: 0.3235 - lr: 5.0000e-05\n",
      "Epoch 133/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9145 - accuracy: 0.3574 - val_loss: 2.0210 - val_accuracy: 0.3237 - lr: 5.0000e-05\n",
      "Epoch 134/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.9142 - accuracy: 0.3573 - val_loss: 2.0209 - val_accuracy: 0.3242 - lr: 5.0000e-05\n",
      "Epoch 135/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9137 - accuracy: 0.3578 - val_loss: 2.0206 - val_accuracy: 0.3240 - lr: 5.0000e-05\n",
      "Epoch 136/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9136 - accuracy: 0.3577 - val_loss: 2.0206 - val_accuracy: 0.3240 - lr: 5.0000e-05\n",
      "Epoch 137/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9132 - accuracy: 0.3579 - val_loss: 2.0201 - val_accuracy: 0.3243 - lr: 5.0000e-05\n",
      "Epoch 138/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.9128 - accuracy: 0.3582 - val_loss: 2.0198 - val_accuracy: 0.3247 - lr: 5.0000e-05\n",
      "Epoch 139/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9124 - accuracy: 0.3580 - val_loss: 2.0199 - val_accuracy: 0.3244 - lr: 5.0000e-05\n",
      "Epoch 140/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9121 - accuracy: 0.3584 - val_loss: 2.0195 - val_accuracy: 0.3246 - lr: 5.0000e-05\n",
      "Epoch 141/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.9119 - accuracy: 0.3582 - val_loss: 2.0191 - val_accuracy: 0.3245 - lr: 5.0000e-05\n",
      "Epoch 142/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9117 - accuracy: 0.3585 - val_loss: 2.0190 - val_accuracy: 0.3252 - lr: 5.0000e-05\n",
      "Epoch 143/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.9113 - accuracy: 0.3585 - val_loss: 2.0186 - val_accuracy: 0.3248 - lr: 5.0000e-05\n",
      "Epoch 144/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.9109 - accuracy: 0.3586 - val_loss: 2.0184 - val_accuracy: 0.3247 - lr: 5.0000e-05\n",
      "Epoch 145/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.9105 - accuracy: 0.3587 - val_loss: 2.0181 - val_accuracy: 0.3254 - lr: 5.0000e-05\n",
      "Epoch 146/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.9102 - accuracy: 0.3591 - val_loss: 2.0176 - val_accuracy: 0.3258 - lr: 5.0000e-05\n",
      "Epoch 147/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.9100 - accuracy: 0.3587 - val_loss: 2.0173 - val_accuracy: 0.3263 - lr: 5.0000e-05\n",
      "Epoch 148/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.9097 - accuracy: 0.3591 - val_loss: 2.0174 - val_accuracy: 0.3262 - lr: 5.0000e-05\n",
      "Epoch 149/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.9096 - accuracy: 0.3585 - val_loss: 2.0170 - val_accuracy: 0.3265 - lr: 5.0000e-05\n",
      "Epoch 150/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.9092 - accuracy: 0.3592 - val_loss: 2.0168 - val_accuracy: 0.3262 - lr: 5.0000e-05\n",
      "Epoch 151/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9088 - accuracy: 0.3589 - val_loss: 2.0166 - val_accuracy: 0.3267 - lr: 5.0000e-05\n",
      "Epoch 152/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.9087 - accuracy: 0.3593 - val_loss: 2.0162 - val_accuracy: 0.3265 - lr: 5.0000e-05\n",
      "Epoch 153/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.9082 - accuracy: 0.3596 - val_loss: 2.0164 - val_accuracy: 0.3254 - lr: 5.0000e-05\n",
      "Epoch 154/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.9080 - accuracy: 0.3596 - val_loss: 2.0157 - val_accuracy: 0.3267 - lr: 5.0000e-05\n",
      "Epoch 155/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9078 - accuracy: 0.3598 - val_loss: 2.0154 - val_accuracy: 0.3267 - lr: 5.0000e-05\n",
      "Epoch 156/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.9075 - accuracy: 0.3602 - val_loss: 2.0153 - val_accuracy: 0.3265 - lr: 5.0000e-05\n",
      "Epoch 157/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9071 - accuracy: 0.3598 - val_loss: 2.0151 - val_accuracy: 0.3263 - lr: 5.0000e-05\n",
      "Epoch 158/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9068 - accuracy: 0.3603 - val_loss: 2.0147 - val_accuracy: 0.3273 - lr: 5.0000e-05\n",
      "Epoch 159/960\n",
      "13/13 [==============================] - 136s 10s/step - loss: 1.9068 - accuracy: 0.3601 - val_loss: 2.0148 - val_accuracy: 0.3266 - lr: 5.0000e-05\n",
      "Epoch 160/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.9063 - accuracy: 0.3605 - val_loss: 2.0142 - val_accuracy: 0.3273 - lr: 5.0000e-05\n",
      "Epoch 161/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9061 - accuracy: 0.3605 - val_loss: 2.0146 - val_accuracy: 0.3268 - lr: 5.0000e-05\n",
      "Epoch 162/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9060 - accuracy: 0.3605 - val_loss: 2.0143 - val_accuracy: 0.3265 - lr: 5.0000e-05\n",
      "Epoch 163/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.9055 - accuracy: 0.3605 - val_loss: 2.0140 - val_accuracy: 0.3272 - lr: 5.0000e-05\n",
      "Epoch 164/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.9054 - accuracy: 0.3606 - val_loss: 2.0139 - val_accuracy: 0.3268 - lr: 5.0000e-05\n",
      "Epoch 165/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9050 - accuracy: 0.3608 - val_loss: 2.0131 - val_accuracy: 0.3277 - lr: 5.0000e-05\n",
      "Epoch 166/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.9047 - accuracy: 0.3611 - val_loss: 2.0130 - val_accuracy: 0.3274 - lr: 5.0000e-05\n",
      "Epoch 167/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9043 - accuracy: 0.3609 - val_loss: 2.0127 - val_accuracy: 0.3277 - lr: 5.0000e-05\n",
      "Epoch 168/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9042 - accuracy: 0.3609 - val_loss: 2.0126 - val_accuracy: 0.3276 - lr: 5.0000e-05\n",
      "Epoch 169/960\n",
      "13/13 [==============================] - 112s 9s/step - loss: 1.9036 - accuracy: 0.3613 - val_loss: 2.0124 - val_accuracy: 0.3275 - lr: 5.0000e-05\n",
      "Epoch 170/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9035 - accuracy: 0.3609 - val_loss: 2.0120 - val_accuracy: 0.3275 - lr: 5.0000e-05\n",
      "Epoch 171/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.9030 - accuracy: 0.3615 - val_loss: 2.0116 - val_accuracy: 0.3280 - lr: 5.0000e-05\n",
      "Epoch 172/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.9027 - accuracy: 0.3618 - val_loss: 2.0114 - val_accuracy: 0.3284 - lr: 5.0000e-05\n",
      "Epoch 173/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.9024 - accuracy: 0.3618 - val_loss: 2.0111 - val_accuracy: 0.3282 - lr: 5.0000e-05\n",
      "Epoch 174/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9021 - accuracy: 0.3617 - val_loss: 2.0109 - val_accuracy: 0.3289 - lr: 5.0000e-05\n",
      "Epoch 175/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.9018 - accuracy: 0.3620 - val_loss: 2.0108 - val_accuracy: 0.3282 - lr: 5.0000e-05\n",
      "Epoch 176/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.9014 - accuracy: 0.3616 - val_loss: 2.0103 - val_accuracy: 0.3282 - lr: 5.0000e-05\n",
      "Epoch 177/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.9013 - accuracy: 0.3618 - val_loss: 2.0102 - val_accuracy: 0.3289 - lr: 5.0000e-05\n",
      "Epoch 178/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.9008 - accuracy: 0.3623 - val_loss: 2.0101 - val_accuracy: 0.3287 - lr: 5.0000e-05\n",
      "Epoch 179/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.9004 - accuracy: 0.3625 - val_loss: 2.0098 - val_accuracy: 0.3286 - lr: 5.0000e-05\n",
      "Epoch 180/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.9002 - accuracy: 0.3623 - val_loss: 2.0092 - val_accuracy: 0.3294 - lr: 5.0000e-05\n",
      "Epoch 181/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8999 - accuracy: 0.3625 - val_loss: 2.0089 - val_accuracy: 0.3292 - lr: 5.0000e-05\n",
      "Epoch 182/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8998 - accuracy: 0.3627 - val_loss: 2.0089 - val_accuracy: 0.3298 - lr: 5.0000e-05\n",
      "Epoch 183/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8992 - accuracy: 0.3625 - val_loss: 2.0081 - val_accuracy: 0.3289 - lr: 5.0000e-05\n",
      "Epoch 184/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8989 - accuracy: 0.3624 - val_loss: 2.0080 - val_accuracy: 0.3291 - lr: 5.0000e-05\n",
      "Epoch 185/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8986 - accuracy: 0.3627 - val_loss: 2.0083 - val_accuracy: 0.3288 - lr: 5.0000e-05\n",
      "Epoch 186/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8984 - accuracy: 0.3629 - val_loss: 2.0075 - val_accuracy: 0.3293 - lr: 5.0000e-05\n",
      "Epoch 187/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8981 - accuracy: 0.3630 - val_loss: 2.0075 - val_accuracy: 0.3296 - lr: 5.0000e-05\n",
      "Epoch 188/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8978 - accuracy: 0.3634 - val_loss: 2.0076 - val_accuracy: 0.3292 - lr: 5.0000e-05\n",
      "Epoch 189/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8973 - accuracy: 0.3632 - val_loss: 2.0067 - val_accuracy: 0.3301 - lr: 5.0000e-05\n",
      "Epoch 190/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8971 - accuracy: 0.3636 - val_loss: 2.0061 - val_accuracy: 0.3301 - lr: 5.0000e-05\n",
      "Epoch 191/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8968 - accuracy: 0.3635 - val_loss: 2.0057 - val_accuracy: 0.3303 - lr: 5.0000e-05\n",
      "Epoch 192/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8963 - accuracy: 0.3636 - val_loss: 2.0056 - val_accuracy: 0.3304 - lr: 5.0000e-05\n",
      "Epoch 193/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8960 - accuracy: 0.3638 - val_loss: 2.0053 - val_accuracy: 0.3305 - lr: 5.0000e-05\n",
      "Epoch 194/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8958 - accuracy: 0.3645 - val_loss: 2.0048 - val_accuracy: 0.3308 - lr: 5.0000e-05\n",
      "Epoch 195/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8953 - accuracy: 0.3647 - val_loss: 2.0046 - val_accuracy: 0.3304 - lr: 5.0000e-05\n",
      "Epoch 196/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8949 - accuracy: 0.3645 - val_loss: 2.0044 - val_accuracy: 0.3308 - lr: 5.0000e-05\n",
      "Epoch 197/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8953 - accuracy: 0.3647 - val_loss: 2.0047 - val_accuracy: 0.3311 - lr: 5.0000e-05\n",
      "Epoch 198/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8947 - accuracy: 0.3644 - val_loss: 2.0038 - val_accuracy: 0.3303 - lr: 5.0000e-05\n",
      "Epoch 199/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8942 - accuracy: 0.3649 - val_loss: 2.0040 - val_accuracy: 0.3310 - lr: 5.0000e-05\n",
      "Epoch 200/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8940 - accuracy: 0.3646Model saved at epoch 200\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8940 - accuracy: 0.3646 - val_loss: 2.0037 - val_accuracy: 0.3315 - lr: 5.0000e-05\n",
      "Epoch 201/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8937 - accuracy: 0.3649 - val_loss: 2.0028 - val_accuracy: 0.3313 - lr: 5.0000e-05\n",
      "Epoch 202/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8931 - accuracy: 0.3649 - val_loss: 2.0027 - val_accuracy: 0.3313 - lr: 5.0000e-05\n",
      "Epoch 203/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8928 - accuracy: 0.3650 - val_loss: 2.0025 - val_accuracy: 0.3310 - lr: 5.0000e-05\n",
      "Epoch 204/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8927 - accuracy: 0.3654 - val_loss: 2.0032 - val_accuracy: 0.3312 - lr: 5.0000e-05\n",
      "Epoch 205/960\n",
      "13/13 [==============================] - 124s 9s/step - loss: 1.8928 - accuracy: 0.3649 - val_loss: 2.0023 - val_accuracy: 0.3317 - lr: 5.0000e-05\n",
      "Epoch 206/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8922 - accuracy: 0.3654 - val_loss: 2.0021 - val_accuracy: 0.3312 - lr: 5.0000e-05\n",
      "Epoch 207/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8918 - accuracy: 0.3654 - val_loss: 2.0013 - val_accuracy: 0.3315 - lr: 5.0000e-05\n",
      "Epoch 208/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8916 - accuracy: 0.3653 - val_loss: 2.0015 - val_accuracy: 0.3317 - lr: 5.0000e-05\n",
      "Epoch 209/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8910 - accuracy: 0.3657 - val_loss: 2.0007 - val_accuracy: 0.3319 - lr: 5.0000e-05\n",
      "Epoch 210/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8906 - accuracy: 0.3664 - val_loss: 2.0006 - val_accuracy: 0.3316 - lr: 5.0000e-05\n",
      "Epoch 211/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8906 - accuracy: 0.3661 - val_loss: 2.0010 - val_accuracy: 0.3318 - lr: 5.0000e-05\n",
      "Epoch 212/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8904 - accuracy: 0.3660 - val_loss: 2.0000 - val_accuracy: 0.3326 - lr: 5.0000e-05\n",
      "Epoch 213/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8898 - accuracy: 0.3668 - val_loss: 1.9998 - val_accuracy: 0.3323 - lr: 5.0000e-05\n",
      "Epoch 214/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8896 - accuracy: 0.3662 - val_loss: 1.9992 - val_accuracy: 0.3326 - lr: 5.0000e-05\n",
      "Epoch 215/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8894 - accuracy: 0.3665 - val_loss: 1.9992 - val_accuracy: 0.3322 - lr: 5.0000e-05\n",
      "Epoch 216/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8892 - accuracy: 0.3662 - val_loss: 1.9989 - val_accuracy: 0.3322 - lr: 5.0000e-05\n",
      "Epoch 217/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8887 - accuracy: 0.3667 - val_loss: 1.9990 - val_accuracy: 0.3340 - lr: 5.0000e-05\n",
      "Epoch 218/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8886 - accuracy: 0.3667 - val_loss: 1.9984 - val_accuracy: 0.3328 - lr: 5.0000e-05\n",
      "Epoch 219/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8881 - accuracy: 0.3663 - val_loss: 1.9984 - val_accuracy: 0.3312 - lr: 5.0000e-05\n",
      "Epoch 220/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8881 - accuracy: 0.3666 - val_loss: 1.9980 - val_accuracy: 0.3330 - lr: 5.0000e-05\n",
      "Epoch 221/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8878 - accuracy: 0.3667 - val_loss: 1.9976 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 222/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8872 - accuracy: 0.3668 - val_loss: 1.9972 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 223/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8871 - accuracy: 0.3676 - val_loss: 1.9974 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 224/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8870 - accuracy: 0.3670 - val_loss: 1.9970 - val_accuracy: 0.3339 - lr: 5.0000e-05\n",
      "Epoch 225/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8869 - accuracy: 0.3669 - val_loss: 1.9975 - val_accuracy: 0.3320 - lr: 5.0000e-05\n",
      "Epoch 226/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8867 - accuracy: 0.3672 - val_loss: 1.9963 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 227/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8860 - accuracy: 0.3674 - val_loss: 1.9964 - val_accuracy: 0.3339 - lr: 5.0000e-05\n",
      "Epoch 228/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8857 - accuracy: 0.3676 - val_loss: 1.9959 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 229/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8852 - accuracy: 0.3679 - val_loss: 1.9953 - val_accuracy: 0.3332 - lr: 5.0000e-05\n",
      "Epoch 230/960\n",
      "13/13 [==============================] - 158s 12s/step - loss: 1.8850 - accuracy: 0.3679 - val_loss: 1.9960 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 231/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8848 - accuracy: 0.3680 - val_loss: 1.9950 - val_accuracy: 0.3337 - lr: 5.0000e-05\n",
      "Epoch 232/960\n",
      "13/13 [==============================] - 158s 12s/step - loss: 1.8846 - accuracy: 0.3677 - val_loss: 1.9961 - val_accuracy: 0.3338 - lr: 5.0000e-05\n",
      "Epoch 233/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8847 - accuracy: 0.3677 - val_loss: 1.9957 - val_accuracy: 0.3324 - lr: 5.0000e-05\n",
      "Epoch 234/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8844 - accuracy: 0.3677 - val_loss: 1.9941 - val_accuracy: 0.3338 - lr: 5.0000e-05\n",
      "Epoch 235/960\n",
      "13/13 [==============================] - 167s 13s/step - loss: 1.8841 - accuracy: 0.3677 - val_loss: 1.9940 - val_accuracy: 0.3343 - lr: 5.0000e-05\n",
      "Epoch 236/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8835 - accuracy: 0.3679 - val_loss: 1.9936 - val_accuracy: 0.3342 - lr: 5.0000e-05\n",
      "Epoch 237/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8828 - accuracy: 0.3680 - val_loss: 1.9935 - val_accuracy: 0.3345 - lr: 5.0000e-05\n",
      "Epoch 238/960\n",
      "13/13 [==============================] - 148s 12s/step - loss: 1.8827 - accuracy: 0.3683 - val_loss: 1.9929 - val_accuracy: 0.3354 - lr: 5.0000e-05\n",
      "Epoch 239/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8829 - accuracy: 0.3682 - val_loss: 1.9925 - val_accuracy: 0.3353 - lr: 5.0000e-05\n",
      "Epoch 240/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8824 - accuracy: 0.3681 - val_loss: 1.9940 - val_accuracy: 0.3334 - lr: 5.0000e-05\n",
      "Epoch 241/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8826 - accuracy: 0.3680 - val_loss: 1.9931 - val_accuracy: 0.3352 - lr: 5.0000e-05\n",
      "Epoch 242/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8823 - accuracy: 0.3685 - val_loss: 1.9921 - val_accuracy: 0.3354 - lr: 5.0000e-05\n",
      "Epoch 243/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8815 - accuracy: 0.3686 - val_loss: 1.9914 - val_accuracy: 0.3347 - lr: 5.0000e-05\n",
      "Epoch 244/960\n",
      "13/13 [==============================] - 129s 9s/step - loss: 1.8810 - accuracy: 0.3682 - val_loss: 1.9916 - val_accuracy: 0.3346 - lr: 5.0000e-05\n",
      "Epoch 245/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8808 - accuracy: 0.3686 - val_loss: 1.9915 - val_accuracy: 0.3345 - lr: 5.0000e-05\n",
      "Epoch 246/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8805 - accuracy: 0.3687 - val_loss: 1.9910 - val_accuracy: 0.3351 - lr: 5.0000e-05\n",
      "Epoch 247/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8804 - accuracy: 0.3682 - val_loss: 1.9911 - val_accuracy: 0.3343 - lr: 5.0000e-05\n",
      "Epoch 248/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8804 - accuracy: 0.3691 - val_loss: 1.9907 - val_accuracy: 0.3360 - lr: 5.0000e-05\n",
      "Epoch 249/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8798 - accuracy: 0.3686 - val_loss: 1.9902 - val_accuracy: 0.3355 - lr: 5.0000e-05\n",
      "Epoch 250/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8792 - accuracy: 0.3687 - val_loss: 1.9898 - val_accuracy: 0.3359 - lr: 5.0000e-05\n",
      "Epoch 251/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8790 - accuracy: 0.3691 - val_loss: 1.9903 - val_accuracy: 0.3353 - lr: 5.0000e-05\n",
      "Epoch 252/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8788 - accuracy: 0.3692 - val_loss: 1.9895 - val_accuracy: 0.3349 - lr: 5.0000e-05\n",
      "Epoch 253/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8786 - accuracy: 0.3692 - val_loss: 1.9893 - val_accuracy: 0.3359 - lr: 5.0000e-05\n",
      "Epoch 254/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8780 - accuracy: 0.3692 - val_loss: 1.9892 - val_accuracy: 0.3354 - lr: 5.0000e-05\n",
      "Epoch 255/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8780 - accuracy: 0.3695 - val_loss: 1.9897 - val_accuracy: 0.3347 - lr: 5.0000e-05\n",
      "Epoch 256/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8780 - accuracy: 0.3691 - val_loss: 1.9892 - val_accuracy: 0.3353 - lr: 5.0000e-05\n",
      "Epoch 257/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8777 - accuracy: 0.3695 - val_loss: 1.9897 - val_accuracy: 0.3355 - lr: 5.0000e-05\n",
      "Epoch 258/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8776 - accuracy: 0.3694 - val_loss: 1.9884 - val_accuracy: 0.3360 - lr: 5.0000e-05\n",
      "Epoch 259/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8771 - accuracy: 0.3695 - val_loss: 1.9879 - val_accuracy: 0.3358 - lr: 5.0000e-05\n",
      "Epoch 260/960\n",
      "13/13 [==============================] - 147s 11s/step - loss: 1.8765 - accuracy: 0.3698 - val_loss: 1.9872 - val_accuracy: 0.3361 - lr: 5.0000e-05\n",
      "Epoch 261/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8763 - accuracy: 0.3697 - val_loss: 1.9872 - val_accuracy: 0.3362 - lr: 5.0000e-05\n",
      "Epoch 262/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8761 - accuracy: 0.3698 - val_loss: 1.9872 - val_accuracy: 0.3364 - lr: 5.0000e-05\n",
      "Epoch 263/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8762 - accuracy: 0.3697 - val_loss: 1.9880 - val_accuracy: 0.3364 - lr: 5.0000e-05\n",
      "Epoch 264/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8768 - accuracy: 0.3698 - val_loss: 1.9878 - val_accuracy: 0.3371 - lr: 5.0000e-05\n",
      "Epoch 265/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8758 - accuracy: 0.3697 - val_loss: 1.9865 - val_accuracy: 0.3367 - lr: 5.0000e-05\n",
      "Epoch 266/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8749 - accuracy: 0.3700 - val_loss: 1.9862 - val_accuracy: 0.3378 - lr: 5.0000e-05\n",
      "Epoch 267/960\n",
      "13/13 [==============================] - 127s 9s/step - loss: 1.8751 - accuracy: 0.3703 - val_loss: 1.9866 - val_accuracy: 0.3367 - lr: 5.0000e-05\n",
      "Epoch 268/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8745 - accuracy: 0.3702 - val_loss: 1.9861 - val_accuracy: 0.3368 - lr: 5.0000e-05\n",
      "Epoch 269/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8744 - accuracy: 0.3703 - val_loss: 1.9855 - val_accuracy: 0.3360 - lr: 5.0000e-05\n",
      "Epoch 270/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8739 - accuracy: 0.3707 - val_loss: 1.9856 - val_accuracy: 0.3374 - lr: 5.0000e-05\n",
      "Epoch 271/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8735 - accuracy: 0.3700 - val_loss: 1.9852 - val_accuracy: 0.3369 - lr: 5.0000e-05\n",
      "Epoch 272/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8735 - accuracy: 0.3706 - val_loss: 1.9860 - val_accuracy: 0.3369 - lr: 5.0000e-05\n",
      "Epoch 273/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8738 - accuracy: 0.3708 - val_loss: 1.9855 - val_accuracy: 0.3369 - lr: 5.0000e-05\n",
      "Epoch 274/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8733 - accuracy: 0.3705 - val_loss: 1.9844 - val_accuracy: 0.3369 - lr: 5.0000e-05\n",
      "Epoch 275/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8727 - accuracy: 0.3710 - val_loss: 1.9840 - val_accuracy: 0.3372 - lr: 5.0000e-05\n",
      "Epoch 276/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8727 - accuracy: 0.3712 - val_loss: 1.9846 - val_accuracy: 0.3380 - lr: 5.0000e-05\n",
      "Epoch 277/960\n",
      "13/13 [==============================] - 111s 9s/step - loss: 1.8725 - accuracy: 0.3704 - val_loss: 1.9847 - val_accuracy: 0.3384 - lr: 5.0000e-05\n",
      "Epoch 278/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8727 - accuracy: 0.3709 - val_loss: 1.9842 - val_accuracy: 0.3370 - lr: 5.0000e-05\n",
      "Epoch 279/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8722 - accuracy: 0.3711 - val_loss: 1.9846 - val_accuracy: 0.3382 - lr: 5.0000e-05\n",
      "Epoch 280/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8722 - accuracy: 0.3708 - val_loss: 1.9829 - val_accuracy: 0.3378 - lr: 5.0000e-05\n",
      "Epoch 281/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8714 - accuracy: 0.3709 - val_loss: 1.9829 - val_accuracy: 0.3382 - lr: 5.0000e-05\n",
      "Epoch 282/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8709 - accuracy: 0.3713 - val_loss: 1.9827 - val_accuracy: 0.3375 - lr: 5.0000e-05\n",
      "Epoch 283/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8709 - accuracy: 0.3717 - val_loss: 1.9834 - val_accuracy: 0.3383 - lr: 5.0000e-05\n",
      "Epoch 284/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8707 - accuracy: 0.3710 - val_loss: 1.9822 - val_accuracy: 0.3381 - lr: 5.0000e-05\n",
      "Epoch 285/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8703 - accuracy: 0.3715 - val_loss: 1.9824 - val_accuracy: 0.3383 - lr: 5.0000e-05\n",
      "Epoch 286/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8699 - accuracy: 0.3719 - val_loss: 1.9821 - val_accuracy: 0.3382 - lr: 5.0000e-05\n",
      "Epoch 287/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8700 - accuracy: 0.3713 - val_loss: 1.9820 - val_accuracy: 0.3375 - lr: 5.0000e-05\n",
      "Epoch 288/960\n",
      "13/13 [==============================] - 124s 9s/step - loss: 1.8695 - accuracy: 0.3718 - val_loss: 1.9815 - val_accuracy: 0.3381 - lr: 5.0000e-05\n",
      "Epoch 289/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8693 - accuracy: 0.3719 - val_loss: 1.9813 - val_accuracy: 0.3389 - lr: 5.0000e-05\n",
      "Epoch 290/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8687 - accuracy: 0.3719 - val_loss: 1.9807 - val_accuracy: 0.3377 - lr: 5.0000e-05\n",
      "Epoch 291/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8684 - accuracy: 0.3722 - val_loss: 1.9808 - val_accuracy: 0.3390 - lr: 5.0000e-05\n",
      "Epoch 292/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8684 - accuracy: 0.3727 - val_loss: 1.9812 - val_accuracy: 0.3376 - lr: 5.0000e-05\n",
      "Epoch 293/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8687 - accuracy: 0.3723 - val_loss: 1.9807 - val_accuracy: 0.3385 - lr: 5.0000e-05\n",
      "Epoch 294/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8677 - accuracy: 0.3722 - val_loss: 1.9804 - val_accuracy: 0.3389 - lr: 5.0000e-05\n",
      "Epoch 295/960\n",
      "13/13 [==============================] - 140s 10s/step - loss: 1.8683 - accuracy: 0.3726 - val_loss: 1.9807 - val_accuracy: 0.3395 - lr: 5.0000e-05\n",
      "Epoch 296/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8674 - accuracy: 0.3722 - val_loss: 1.9799 - val_accuracy: 0.3386 - lr: 5.0000e-05\n",
      "Epoch 297/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8672 - accuracy: 0.3730 - val_loss: 1.9808 - val_accuracy: 0.3390 - lr: 5.0000e-05\n",
      "Epoch 298/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8676 - accuracy: 0.3730 - val_loss: 1.9813 - val_accuracy: 0.3390 - lr: 5.0000e-05\n",
      "Epoch 299/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8674 - accuracy: 0.3728 - val_loss: 1.9808 - val_accuracy: 0.3401 - lr: 5.0000e-05\n",
      "Epoch 300/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8673 - accuracy: 0.3721Model saved at epoch 300\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8673 - accuracy: 0.3721 - val_loss: 1.9805 - val_accuracy: 0.3384 - lr: 5.0000e-05\n",
      "Epoch 301/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8665 - accuracy: 0.3731 - val_loss: 1.9784 - val_accuracy: 0.3392 - lr: 5.0000e-05\n",
      "Epoch 302/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8658 - accuracy: 0.3725 - val_loss: 1.9791 - val_accuracy: 0.3390 - lr: 5.0000e-05\n",
      "Epoch 303/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8656 - accuracy: 0.3732 - val_loss: 1.9783 - val_accuracy: 0.3389 - lr: 5.0000e-05\n",
      "Epoch 304/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8653 - accuracy: 0.3728 - val_loss: 1.9784 - val_accuracy: 0.3387 - lr: 5.0000e-05\n",
      "Epoch 305/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8650 - accuracy: 0.3730 - val_loss: 1.9776 - val_accuracy: 0.3404 - lr: 5.0000e-05\n",
      "Epoch 306/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8646 - accuracy: 0.3733 - val_loss: 1.9774 - val_accuracy: 0.3387 - lr: 5.0000e-05\n",
      "Epoch 307/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8648 - accuracy: 0.3732 - val_loss: 1.9795 - val_accuracy: 0.3395 - lr: 5.0000e-05\n",
      "Epoch 308/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8646 - accuracy: 0.3732 - val_loss: 1.9781 - val_accuracy: 0.3403 - lr: 5.0000e-05\n",
      "Epoch 309/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8640 - accuracy: 0.3730 - val_loss: 1.9769 - val_accuracy: 0.3401 - lr: 5.0000e-05\n",
      "Epoch 310/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8636 - accuracy: 0.3739 - val_loss: 1.9769 - val_accuracy: 0.3391 - lr: 5.0000e-05\n",
      "Epoch 311/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8639 - accuracy: 0.3735 - val_loss: 1.9773 - val_accuracy: 0.3403 - lr: 5.0000e-05\n",
      "Epoch 312/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8637 - accuracy: 0.3734 - val_loss: 1.9764 - val_accuracy: 0.3393 - lr: 5.0000e-05\n",
      "Epoch 313/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8641 - accuracy: 0.3737 - val_loss: 1.9759 - val_accuracy: 0.3403 - lr: 5.0000e-05\n",
      "Epoch 314/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8630 - accuracy: 0.3737 - val_loss: 1.9764 - val_accuracy: 0.3413 - lr: 5.0000e-05\n",
      "Epoch 315/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8624 - accuracy: 0.3739 - val_loss: 1.9757 - val_accuracy: 0.3404 - lr: 5.0000e-05\n",
      "Epoch 316/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8623 - accuracy: 0.3741 - val_loss: 1.9759 - val_accuracy: 0.3403 - lr: 5.0000e-05\n",
      "Epoch 317/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8620 - accuracy: 0.3744 - val_loss: 1.9757 - val_accuracy: 0.3409 - lr: 5.0000e-05\n",
      "Epoch 318/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8622 - accuracy: 0.3744 - val_loss: 1.9750 - val_accuracy: 0.3404 - lr: 5.0000e-05\n",
      "Epoch 319/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8620 - accuracy: 0.3736 - val_loss: 1.9745 - val_accuracy: 0.3403 - lr: 5.0000e-05\n",
      "Epoch 320/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8613 - accuracy: 0.3743 - val_loss: 1.9747 - val_accuracy: 0.3402 - lr: 5.0000e-05\n",
      "Epoch 321/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8611 - accuracy: 0.3744 - val_loss: 1.9751 - val_accuracy: 0.3402 - lr: 5.0000e-05\n",
      "Epoch 322/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8610 - accuracy: 0.3747 - val_loss: 1.9745 - val_accuracy: 0.3410 - lr: 5.0000e-05\n",
      "Epoch 323/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8605 - accuracy: 0.3750 - val_loss: 1.9739 - val_accuracy: 0.3416 - lr: 5.0000e-05\n",
      "Epoch 324/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8601 - accuracy: 0.3751 - val_loss: 1.9738 - val_accuracy: 0.3397 - lr: 5.0000e-05\n",
      "Epoch 325/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8598 - accuracy: 0.3751 - val_loss: 1.9736 - val_accuracy: 0.3411 - lr: 5.0000e-05\n",
      "Epoch 326/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8600 - accuracy: 0.3744 - val_loss: 1.9738 - val_accuracy: 0.3415 - lr: 5.0000e-05\n",
      "Epoch 327/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8598 - accuracy: 0.3755 - val_loss: 1.9737 - val_accuracy: 0.3410 - lr: 5.0000e-05\n",
      "Epoch 328/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8595 - accuracy: 0.3753 - val_loss: 1.9730 - val_accuracy: 0.3420 - lr: 5.0000e-05\n",
      "Epoch 329/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8593 - accuracy: 0.3747 - val_loss: 1.9733 - val_accuracy: 0.3419 - lr: 5.0000e-05\n",
      "Epoch 330/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8589 - accuracy: 0.3752 - val_loss: 1.9723 - val_accuracy: 0.3423 - lr: 5.0000e-05\n",
      "Epoch 331/960\n",
      "13/13 [==============================] - 112s 9s/step - loss: 1.8588 - accuracy: 0.3756 - val_loss: 1.9732 - val_accuracy: 0.3419 - lr: 5.0000e-05\n",
      "Epoch 332/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8585 - accuracy: 0.3748 - val_loss: 1.9731 - val_accuracy: 0.3420 - lr: 5.0000e-05\n",
      "Epoch 333/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8582 - accuracy: 0.3751 - val_loss: 1.9717 - val_accuracy: 0.3420 - lr: 5.0000e-05\n",
      "Epoch 334/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8582 - accuracy: 0.3753 - val_loss: 1.9719 - val_accuracy: 0.3406 - lr: 5.0000e-05\n",
      "Epoch 335/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8581 - accuracy: 0.3752 - val_loss: 1.9729 - val_accuracy: 0.3423 - lr: 5.0000e-05\n",
      "Epoch 336/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8576 - accuracy: 0.3759 - val_loss: 1.9719 - val_accuracy: 0.3419 - lr: 5.0000e-05\n",
      "Epoch 337/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8576 - accuracy: 0.3752 - val_loss: 1.9716 - val_accuracy: 0.3432 - lr: 5.0000e-05\n",
      "Epoch 338/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8567 - accuracy: 0.3763 - val_loss: 1.9706 - val_accuracy: 0.3421 - lr: 5.0000e-05\n",
      "Epoch 339/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8566 - accuracy: 0.3757 - val_loss: 1.9710 - val_accuracy: 0.3432 - lr: 5.0000e-05\n",
      "Epoch 340/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8563 - accuracy: 0.3755 - val_loss: 1.9703 - val_accuracy: 0.3420 - lr: 5.0000e-05\n",
      "Epoch 341/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8559 - accuracy: 0.3761 - val_loss: 1.9710 - val_accuracy: 0.3423 - lr: 5.0000e-05\n",
      "Epoch 342/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8558 - accuracy: 0.3761 - val_loss: 1.9716 - val_accuracy: 0.3420 - lr: 5.0000e-05\n",
      "Epoch 343/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8560 - accuracy: 0.3759 - val_loss: 1.9701 - val_accuracy: 0.3422 - lr: 5.0000e-05\n",
      "Epoch 344/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8553 - accuracy: 0.3764 - val_loss: 1.9695 - val_accuracy: 0.3426 - lr: 5.0000e-05\n",
      "Epoch 345/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8556 - accuracy: 0.3762 - val_loss: 1.9693 - val_accuracy: 0.3426 - lr: 5.0000e-05\n",
      "Epoch 346/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8548 - accuracy: 0.3766 - val_loss: 1.9689 - val_accuracy: 0.3427 - lr: 5.0000e-05\n",
      "Epoch 347/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8547 - accuracy: 0.3766 - val_loss: 1.9694 - val_accuracy: 0.3426 - lr: 5.0000e-05\n",
      "Epoch 348/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8551 - accuracy: 0.3765 - val_loss: 1.9684 - val_accuracy: 0.3431 - lr: 5.0000e-05\n",
      "Epoch 349/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8540 - accuracy: 0.3768 - val_loss: 1.9688 - val_accuracy: 0.3423 - lr: 5.0000e-05\n",
      "Epoch 350/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8537 - accuracy: 0.3772 - val_loss: 1.9684 - val_accuracy: 0.3436 - lr: 5.0000e-05\n",
      "Epoch 351/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8538 - accuracy: 0.3770 - val_loss: 1.9683 - val_accuracy: 0.3429 - lr: 5.0000e-05\n",
      "Epoch 352/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8534 - accuracy: 0.3766 - val_loss: 1.9683 - val_accuracy: 0.3430 - lr: 5.0000e-05\n",
      "Epoch 353/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8529 - accuracy: 0.3776 - val_loss: 1.9675 - val_accuracy: 0.3431 - lr: 5.0000e-05\n",
      "Epoch 354/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8528 - accuracy: 0.3766 - val_loss: 1.9674 - val_accuracy: 0.3442 - lr: 5.0000e-05\n",
      "Epoch 355/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8529 - accuracy: 0.3770 - val_loss: 1.9679 - val_accuracy: 0.3441 - lr: 5.0000e-05\n",
      "Epoch 356/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8522 - accuracy: 0.3775 - val_loss: 1.9672 - val_accuracy: 0.3428 - lr: 5.0000e-05\n",
      "Epoch 357/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8522 - accuracy: 0.3771 - val_loss: 1.9669 - val_accuracy: 0.3436 - lr: 5.0000e-05\n",
      "Epoch 358/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8524 - accuracy: 0.3776 - val_loss: 1.9675 - val_accuracy: 0.3437 - lr: 5.0000e-05\n",
      "Epoch 359/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8515 - accuracy: 0.3775 - val_loss: 1.9668 - val_accuracy: 0.3430 - lr: 5.0000e-05\n",
      "Epoch 360/960\n",
      "13/13 [==============================] - 141s 10s/step - loss: 1.8513 - accuracy: 0.3773 - val_loss: 1.9662 - val_accuracy: 0.3433 - lr: 5.0000e-05\n",
      "Epoch 361/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8511 - accuracy: 0.3776 - val_loss: 1.9668 - val_accuracy: 0.3431 - lr: 5.0000e-05\n",
      "Epoch 362/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8507 - accuracy: 0.3778 - val_loss: 1.9659 - val_accuracy: 0.3440 - lr: 5.0000e-05\n",
      "Epoch 363/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8506 - accuracy: 0.3784 - val_loss: 1.9656 - val_accuracy: 0.3448 - lr: 5.0000e-05\n",
      "Epoch 364/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8503 - accuracy: 0.3779 - val_loss: 1.9659 - val_accuracy: 0.3441 - lr: 5.0000e-05\n",
      "Epoch 365/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8505 - accuracy: 0.3777 - val_loss: 1.9661 - val_accuracy: 0.3429 - lr: 5.0000e-05\n",
      "Epoch 366/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8501 - accuracy: 0.3778 - val_loss: 1.9655 - val_accuracy: 0.3448 - lr: 5.0000e-05\n",
      "Epoch 367/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8498 - accuracy: 0.3780 - val_loss: 1.9648 - val_accuracy: 0.3435 - lr: 5.0000e-05\n",
      "Epoch 368/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8503 - accuracy: 0.3777 - val_loss: 1.9666 - val_accuracy: 0.3445 - lr: 5.0000e-05\n",
      "Epoch 369/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8497 - accuracy: 0.3781 - val_loss: 1.9653 - val_accuracy: 0.3435 - lr: 5.0000e-05\n",
      "Epoch 370/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8493 - accuracy: 0.3780 - val_loss: 1.9645 - val_accuracy: 0.3452 - lr: 5.0000e-05\n",
      "Epoch 371/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8489 - accuracy: 0.3780 - val_loss: 1.9642 - val_accuracy: 0.3450 - lr: 5.0000e-05\n",
      "Epoch 372/960\n",
      "13/13 [==============================] - 112s 9s/step - loss: 1.8489 - accuracy: 0.3786 - val_loss: 1.9646 - val_accuracy: 0.3438 - lr: 5.0000e-05\n",
      "Epoch 373/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8487 - accuracy: 0.3781 - val_loss: 1.9642 - val_accuracy: 0.3450 - lr: 5.0000e-05\n",
      "Epoch 374/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8483 - accuracy: 0.3787 - val_loss: 1.9648 - val_accuracy: 0.3443 - lr: 5.0000e-05\n",
      "Epoch 375/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8486 - accuracy: 0.3779 - val_loss: 1.9642 - val_accuracy: 0.3459 - lr: 5.0000e-05\n",
      "Epoch 376/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8479 - accuracy: 0.3789 - val_loss: 1.9643 - val_accuracy: 0.3446 - lr: 5.0000e-05\n",
      "Epoch 377/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8467 - accuracy: 0.3784 - val_loss: 1.9628 - val_accuracy: 0.3451 - lr: 2.5000e-06\n",
      "Epoch 378/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8462 - accuracy: 0.3792 - val_loss: 1.9627 - val_accuracy: 0.3447 - lr: 2.5000e-06\n",
      "Epoch 379/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8461 - accuracy: 0.3789 - val_loss: 1.9627 - val_accuracy: 0.3447 - lr: 2.5000e-06\n",
      "Epoch 380/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8461 - accuracy: 0.3790 - val_loss: 1.9627 - val_accuracy: 0.3447 - lr: 2.5000e-06\n",
      "Epoch 381/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8460 - accuracy: 0.3791 - val_loss: 1.9626 - val_accuracy: 0.3447 - lr: 2.5000e-06\n",
      "Epoch 382/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8460 - accuracy: 0.3790 - val_loss: 1.9626 - val_accuracy: 0.3443 - lr: 2.5000e-06\n",
      "Epoch 383/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8460 - accuracy: 0.3790 - val_loss: 1.9626 - val_accuracy: 0.3443 - lr: 2.5000e-06\n",
      "Epoch 384/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8460 - accuracy: 0.3789 - val_loss: 1.9626 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 385/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8459 - accuracy: 0.3789 - val_loss: 1.9626 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 386/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9626 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 387/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9626 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 388/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9626 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 389/960\n",
      "13/13 [==============================] - 135s 11s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9626 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 390/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9626 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 391/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 392/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 393/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 394/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8459 - accuracy: 0.3789 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 395/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 396/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8459 - accuracy: 0.3789 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 397/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 398/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 399/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 400/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8459 - accuracy: 0.3790Model saved at epoch 400\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8459 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 401/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8459 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 402/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 403/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 404/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 405/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 406/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 407/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 408/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 409/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 410/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9625 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 411/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 412/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 413/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 414/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 415/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 416/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 417/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 418/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8458 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 419/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 420/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 421/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3440 - lr: 1.0000e-06\n",
      "Epoch 422/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8458 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 423/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8458 - accuracy: 0.3789 - val_loss: 1.9624 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 424/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 425/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 426/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 427/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 428/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8457 - accuracy: 0.3792 - val_loss: 1.9624 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 429/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9624 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 430/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 431/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8457 - accuracy: 0.3792 - val_loss: 1.9624 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 432/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9623 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 433/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9623 - val_accuracy: 0.3440 - lr: 1.0000e-06\n",
      "Epoch 434/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 435/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 436/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9624 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 437/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8457 - accuracy: 0.3790 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 438/960\n",
      "13/13 [==============================] - 135s 11s/step - loss: 1.8457 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3440 - lr: 1.0000e-06\n",
      "Epoch 439/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8457 - accuracy: 0.3792 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 440/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 441/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 442/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 443/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 444/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 445/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9623 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 446/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 447/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8456 - accuracy: 0.3790 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 448/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8456 - accuracy: 0.3790 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 449/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 450/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9623 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 451/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 452/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9623 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 453/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 454/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 455/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 456/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 457/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 458/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 459/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8456 - accuracy: 0.3792 - val_loss: 1.9622 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 460/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 461/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8456 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 462/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8455 - accuracy: 0.3790 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 463/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8455 - accuracy: 0.3792 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 464/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 465/960\n",
      "13/13 [==============================] - 141s 10s/step - loss: 1.8455 - accuracy: 0.3792 - val_loss: 1.9622 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 466/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8455 - accuracy: 0.3790 - val_loss: 1.9622 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 467/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 468/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3441 - lr: 1.0000e-06\n",
      "Epoch 469/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8455 - accuracy: 0.3790 - val_loss: 1.9622 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 470/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 471/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 472/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 473/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8455 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 474/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8455 - accuracy: 0.3791 - val_loss: 1.9622 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 475/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8455 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 476/960\n",
      "13/13 [==============================] - 125s 9s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 477/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 478/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8455 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 479/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 480/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 481/960\n",
      "13/13 [==============================] - 125s 9s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 482/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 483/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8454 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 484/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 485/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 486/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8454 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 487/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 488/960\n",
      "13/13 [==============================] - 134s 11s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 489/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 490/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 491/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 492/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 493/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8454 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 494/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8454 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 495/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8454 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 496/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8454 - accuracy: 0.3793 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 497/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8454 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 498/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8453 - accuracy: 0.3790 - val_loss: 1.9621 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 499/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 500/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8453 - accuracy: 0.3792Model saved at epoch 500\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 501/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9621 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 502/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 503/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3442 - lr: 1.0000e-06\n",
      "Epoch 504/960\n",
      "13/13 [==============================] - 136s 10s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 505/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 506/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 507/960\n",
      "13/13 [==============================] - 124s 9s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 508/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8453 - accuracy: 0.3793 - val_loss: 1.9620 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 509/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 510/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 511/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 512/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 513/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8453 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 514/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8452 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 515/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8452 - accuracy: 0.3791 - val_loss: 1.9620 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 516/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 517/960\n",
      "13/13 [==============================] - 147s 12s/step - loss: 1.8453 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 518/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 519/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9620 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 520/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8452 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 521/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 522/960\n",
      "13/13 [==============================] - 135s 9s/step - loss: 1.8452 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 523/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 524/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 525/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8452 - accuracy: 0.3790 - val_loss: 1.9620 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 526/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8452 - accuracy: 0.3793 - val_loss: 1.9619 - val_accuracy: 0.3443 - lr: 1.0000e-06\n",
      "Epoch 527/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 528/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 529/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8452 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 530/960\n",
      "13/13 [==============================] - 127s 9s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 531/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8452 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 532/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 533/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 534/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8451 - accuracy: 0.3793 - val_loss: 1.9619 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 535/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 536/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 537/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 538/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 539/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 540/960\n",
      "13/13 [==============================] - 136s 10s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 541/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8451 - accuracy: 0.3793 - val_loss: 1.9618 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 542/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9619 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 543/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 544/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 545/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 546/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 547/960\n",
      "13/13 [==============================] - 163s 13s/step - loss: 1.8451 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 548/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8451 - accuracy: 0.3793 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 549/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8451 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 550/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8450 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 551/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 552/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 553/960\n",
      "13/13 [==============================] - 159s 12s/step - loss: 1.8450 - accuracy: 0.3793 - val_loss: 1.9618 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 554/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8450 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 555/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8450 - accuracy: 0.3791 - val_loss: 1.9618 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 556/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8450 - accuracy: 0.3791 - val_loss: 1.9617 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 557/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8450 - accuracy: 0.3793 - val_loss: 1.9618 - val_accuracy: 0.3444 - lr: 1.0000e-06\n",
      "Epoch 558/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 559/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 560/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9617 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 561/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9617 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 562/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 563/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8450 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 564/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8450 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 565/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9618 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 566/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8450 - accuracy: 0.3792 - val_loss: 1.9617 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 567/960\n",
      "13/13 [==============================] - 160s 13s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 568/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 569/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8449 - accuracy: 0.3792 - val_loss: 1.9617 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 570/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8449 - accuracy: 0.3791 - val_loss: 1.9617 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 571/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 572/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 573/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8449 - accuracy: 0.3794 - val_loss: 1.9617 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 574/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8449 - accuracy: 0.3791 - val_loss: 1.9617 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 575/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8449 - accuracy: 0.3794 - val_loss: 1.9617 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 576/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9617 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 577/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8449 - accuracy: 0.3794 - val_loss: 1.9616 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 578/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 579/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 580/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8449 - accuracy: 0.3791 - val_loss: 1.9617 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 581/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8449 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 582/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8449 - accuracy: 0.3792 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 583/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8449 - accuracy: 0.3794 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 584/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 585/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8448 - accuracy: 0.3792 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 586/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8448 - accuracy: 0.3792 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 587/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 588/960\n",
      "13/13 [==============================] - 164s 13s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 589/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 590/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8448 - accuracy: 0.3794 - val_loss: 1.9616 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 591/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 592/960\n",
      "13/13 [==============================] - 158s 12s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 593/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8448 - accuracy: 0.3792 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 594/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8448 - accuracy: 0.3794 - val_loss: 1.9616 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 595/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 596/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8448 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 597/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 598/960\n",
      "13/13 [==============================] - 167s 13s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 599/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 600/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8448 - accuracy: 0.3794Model saved at epoch 600\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8448 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 601/960\n",
      "13/13 [==============================] - 151s 12s/step - loss: 1.8448 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 602/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8447 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 603/960\n",
      "13/13 [==============================] - 135s 11s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 604/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8448 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 605/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9616 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 606/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 607/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8447 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 608/960\n",
      "13/13 [==============================] - 170s 13s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 609/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 610/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8447 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 611/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8447 - accuracy: 0.3795 - val_loss: 1.9615 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 612/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 613/960\n",
      "13/13 [==============================] - 130s 9s/step - loss: 1.8447 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 614/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 615/960\n",
      "13/13 [==============================] - 136s 10s/step - loss: 1.8447 - accuracy: 0.3794 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 616/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 617/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8447 - accuracy: 0.3795 - val_loss: 1.9614 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 618/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8447 - accuracy: 0.3795 - val_loss: 1.9615 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 619/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 620/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 621/960\n",
      "13/13 [==============================] - 148s 12s/step - loss: 1.8447 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3445 - lr: 1.0000e-06\n",
      "Epoch 622/960\n",
      "13/13 [==============================] - 148s 12s/step - loss: 1.8446 - accuracy: 0.3795 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 623/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9615 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 624/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 625/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8446 - accuracy: 0.3794 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 626/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8446 - accuracy: 0.3794 - val_loss: 1.9614 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 627/960\n",
      "13/13 [==============================] - 164s 13s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 628/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8446 - accuracy: 0.3795 - val_loss: 1.9614 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 629/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 630/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 631/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 632/960\n",
      "13/13 [==============================] - 157s 12s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 633/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8446 - accuracy: 0.3795 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 634/960\n",
      "13/13 [==============================] - 163s 13s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 635/960\n",
      "13/13 [==============================] - 129s 9s/step - loss: 1.8446 - accuracy: 0.3794 - val_loss: 1.9614 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 636/960\n",
      "13/13 [==============================] - 152s 12s/step - loss: 1.8446 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 637/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8445 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 638/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8445 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 639/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 640/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 641/960\n",
      "13/13 [==============================] - 148s 12s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 642/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8445 - accuracy: 0.3793 - val_loss: 1.9614 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 643/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 644/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 645/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8445 - accuracy: 0.3795 - val_loss: 1.9613 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 646/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8445 - accuracy: 0.3792 - val_loss: 1.9613 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 647/960\n",
      "13/13 [==============================] - 165s 13s/step - loss: 1.8445 - accuracy: 0.3795 - val_loss: 1.9613 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 648/960\n",
      "13/13 [==============================] - 161s 12s/step - loss: 1.8445 - accuracy: 0.3793 - val_loss: 1.9613 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 649/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 650/960\n",
      "13/13 [==============================] - 159s 12s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 651/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 652/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 653/960\n",
      "13/13 [==============================] - 157s 12s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9613 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 654/960\n",
      "13/13 [==============================] - 161s 11s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 655/960\n",
      "13/13 [==============================] - 158s 12s/step - loss: 1.8445 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 656/960\n",
      "13/13 [==============================] - 151s 12s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 657/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 658/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9613 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 659/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8444 - accuracy: 0.3796 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 660/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8444 - accuracy: 0.3793 - val_loss: 1.9613 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 661/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8444 - accuracy: 0.3793 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 662/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 663/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8444 - accuracy: 0.3793 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 664/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 665/960\n",
      "13/13 [==============================] - 156s 12s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 666/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 667/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 668/960\n",
      "13/13 [==============================] - 140s 9s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 669/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 670/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 671/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 672/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8444 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 673/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 674/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8444 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 675/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 676/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 677/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 678/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 679/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8443 - accuracy: 0.3796 - val_loss: 1.9611 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 680/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 681/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9612 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 682/960\n",
      "13/13 [==============================] - 153s 12s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 683/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 684/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8443 - accuracy: 0.3794 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 685/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8443 - accuracy: 0.3793 - val_loss: 1.9612 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 686/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 687/960\n",
      "13/13 [==============================] - 176s 14s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9612 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 688/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 689/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8443 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3447 - lr: 1.0000e-06\n",
      "Epoch 690/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8442 - accuracy: 0.3796 - val_loss: 1.9611 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 691/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 692/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8442 - accuracy: 0.3793 - val_loss: 1.9611 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 693/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 694/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 695/960\n",
      "13/13 [==============================] - 152s 12s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 696/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 697/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 698/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8442 - accuracy: 0.3796 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 699/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 700/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8442 - accuracy: 0.3795Model saved at epoch 700\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 701/960\n",
      "13/13 [==============================] - 125s 9s/step - loss: 1.8442 - accuracy: 0.3794 - val_loss: 1.9611 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 702/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 703/960\n",
      "13/13 [==============================] - 147s 11s/step - loss: 1.8442 - accuracy: 0.3794 - val_loss: 1.9611 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 704/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 705/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 706/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9611 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 707/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 708/960\n",
      "13/13 [==============================] - 165s 13s/step - loss: 1.8442 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 709/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 710/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8441 - accuracy: 0.3794 - val_loss: 1.9610 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 711/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 712/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 713/960\n",
      "13/13 [==============================] - 145s 10s/step - loss: 1.8441 - accuracy: 0.3797 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 714/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8441 - accuracy: 0.3794 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 715/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 716/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 717/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 718/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 719/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 720/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 721/960\n",
      "13/13 [==============================] - 133s 10s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 722/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9610 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 723/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8441 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 724/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 725/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 726/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8441 - accuracy: 0.3795 - val_loss: 1.9610 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 727/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 728/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 729/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 730/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 731/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 732/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 733/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 734/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 735/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 736/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 737/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 738/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 739/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8440 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 740/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 741/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8440 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 742/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 743/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9609 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 744/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 745/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 746/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9609 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 747/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 748/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 749/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8439 - accuracy: 0.3797 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 750/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 751/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 752/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 753/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 754/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 755/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 756/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 757/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8439 - accuracy: 0.3796 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 758/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9608 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 759/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 760/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8439 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 761/960\n",
      "13/13 [==============================] - 157s 12s/step - loss: 1.8438 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 762/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 763/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 764/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 765/960\n",
      "13/13 [==============================] - 125s 9s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9608 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 766/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 767/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 768/960\n",
      "13/13 [==============================] - 126s 9s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 769/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8438 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 770/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 771/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 772/960\n",
      "13/13 [==============================] - 143s 10s/step - loss: 1.8438 - accuracy: 0.3795 - val_loss: 1.9608 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 773/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8438 - accuracy: 0.3795 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 774/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8438 - accuracy: 0.3798 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 775/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8438 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 776/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8437 - accuracy: 0.3795 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 777/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 778/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8437 - accuracy: 0.3795 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 779/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 780/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 781/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 782/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9607 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 783/960\n",
      "13/13 [==============================] - 123s 9s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 784/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3448 - lr: 1.0000e-06\n",
      "Epoch 785/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9606 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 786/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9607 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 787/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 788/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 789/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 790/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9606 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 791/960\n",
      "13/13 [==============================] - 151s 12s/step - loss: 1.8437 - accuracy: 0.3796 - val_loss: 1.9606 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 792/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8437 - accuracy: 0.3795 - val_loss: 1.9606 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 793/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8437 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 794/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8436 - accuracy: 0.3798 - val_loss: 1.9606 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 795/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8436 - accuracy: 0.3795 - val_loss: 1.9606 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 796/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 797/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8436 - accuracy: 0.3796 - val_loss: 1.9606 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 798/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 799/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 800/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8436 - accuracy: 0.3797Model saved at epoch 800\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 801/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9606 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 802/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8436 - accuracy: 0.3798 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 803/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8436 - accuracy: 0.3796 - val_loss: 1.9606 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 804/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8436 - accuracy: 0.3795 - val_loss: 1.9606 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 805/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8436 - accuracy: 0.3796 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 806/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8436 - accuracy: 0.3798 - val_loss: 1.9606 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 807/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 808/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 809/960\n",
      "13/13 [==============================] - 157s 12s/step - loss: 1.8436 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 810/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 811/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8435 - accuracy: 0.3798 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 812/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8435 - accuracy: 0.3796 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 813/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 814/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3451 - lr: 1.0000e-06\n",
      "Epoch 815/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 816/960\n",
      "13/13 [==============================] - 146s 12s/step - loss: 1.8435 - accuracy: 0.3798 - val_loss: 1.9605 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 817/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8435 - accuracy: 0.3796 - val_loss: 1.9605 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 818/960\n",
      "13/13 [==============================] - 127s 9s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 819/960\n",
      "13/13 [==============================] - 147s 11s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 820/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8435 - accuracy: 0.3796 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 821/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 822/960\n",
      "13/13 [==============================] - 123s 10s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 823/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 824/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8435 - accuracy: 0.3796 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 825/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 826/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8435 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 827/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 828/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8435 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 829/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 830/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 831/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 832/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 833/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 834/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9605 - val_accuracy: 0.3450 - lr: 1.0000e-06\n",
      "Epoch 835/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 836/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8434 - accuracy: 0.3796 - val_loss: 1.9604 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 837/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8434 - accuracy: 0.3795 - val_loss: 1.9604 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 838/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 839/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 840/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 841/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8434 - accuracy: 0.3797 - val_loss: 1.9604 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 842/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8434 - accuracy: 0.3796 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 843/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 844/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 845/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8434 - accuracy: 0.3798 - val_loss: 1.9604 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 846/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8433 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 847/960\n",
      "13/13 [==============================] - 137s 10s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 848/960\n",
      "13/13 [==============================] - 150s 12s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 849/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 850/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8433 - accuracy: 0.3796 - val_loss: 1.9604 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 851/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8433 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 852/960\n",
      "13/13 [==============================] - 155s 12s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 853/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 854/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8433 - accuracy: 0.3796 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 855/960\n",
      "13/13 [==============================] - 167s 13s/step - loss: 1.8433 - accuracy: 0.3796 - val_loss: 1.9603 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 856/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 857/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 858/960\n",
      "13/13 [==============================] - 164s 12s/step - loss: 1.8433 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 859/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8433 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 860/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8433 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 861/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8433 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 862/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 863/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 864/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8432 - accuracy: 0.3799 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 865/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9603 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 866/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 867/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 868/960\n",
      "13/13 [==============================] - 126s 10s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9602 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 869/960\n",
      "13/13 [==============================] - 148s 12s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9603 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 870/960\n",
      "13/13 [==============================] - 146s 11s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 871/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8432 - accuracy: 0.3800 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 872/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 873/960\n",
      "13/13 [==============================] - 156s 12s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 874/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8432 - accuracy: 0.3799 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 875/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9602 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 876/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 877/960\n",
      "13/13 [==============================] - 182s 14s/step - loss: 1.8432 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 878/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8432 - accuracy: 0.3799 - val_loss: 1.9602 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 879/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8432 - accuracy: 0.3797 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 880/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8432 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 881/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8431 - accuracy: 0.3796 - val_loss: 1.9602 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 882/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8431 - accuracy: 0.3799 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 883/960\n",
      "13/13 [==============================] - 116s 9s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 884/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 885/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8431 - accuracy: 0.3797 - val_loss: 1.9602 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 886/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8431 - accuracy: 0.3801 - val_loss: 1.9602 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 887/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8431 - accuracy: 0.3799 - val_loss: 1.9602 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 888/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8431 - accuracy: 0.3797 - val_loss: 1.9601 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 889/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 890/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8431 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 891/960\n",
      "13/13 [==============================] - 165s 13s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 892/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9602 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 893/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8431 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 894/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 895/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 896/960\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8431 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 897/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 898/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8431 - accuracy: 0.3797 - val_loss: 1.9601 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 899/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 900/960\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8430 - accuracy: 0.3799Model saved at epoch 900\n",
      "13/13 [==============================] - 124s 10s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 901/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 902/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 903/960\n",
      "13/13 [==============================] - 136s 11s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3452 - lr: 1.0000e-06\n",
      "Epoch 904/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 905/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 906/960\n",
      "13/13 [==============================] - 138s 11s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 907/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9601 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 908/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8430 - accuracy: 0.3800 - val_loss: 1.9601 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 909/960\n",
      "13/13 [==============================] - 124s 9s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9601 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 910/960\n",
      "13/13 [==============================] - 122s 9s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 911/960\n",
      "13/13 [==============================] - 156s 12s/step - loss: 1.8430 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 912/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8430 - accuracy: 0.3797 - val_loss: 1.9601 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 913/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 914/960\n",
      "13/13 [==============================] - 127s 10s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 915/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8430 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 916/960\n",
      "13/13 [==============================] - 135s 10s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 917/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8429 - accuracy: 0.3797 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 918/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8429 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 919/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8429 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 920/960\n",
      "13/13 [==============================] - 140s 11s/step - loss: 1.8429 - accuracy: 0.3800 - val_loss: 1.9600 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 921/960\n",
      "13/13 [==============================] - 115s 9s/step - loss: 1.8429 - accuracy: 0.3800 - val_loss: 1.9600 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 922/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 923/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 924/960\n",
      "13/13 [==============================] - 113s 9s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 925/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8429 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3458 - lr: 1.0000e-06\n",
      "Epoch 926/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8429 - accuracy: 0.3799 - val_loss: 1.9600 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 927/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8429 - accuracy: 0.3797 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 928/960\n",
      "13/13 [==============================] - 121s 9s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 929/960\n",
      "13/13 [==============================] - 137s 11s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 930/960\n",
      "13/13 [==============================] - 130s 10s/step - loss: 1.8429 - accuracy: 0.3800 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 931/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 932/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8429 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 933/960\n",
      "13/13 [==============================] - 139s 11s/step - loss: 1.8429 - accuracy: 0.3800 - val_loss: 1.9599 - val_accuracy: 0.3458 - lr: 1.0000e-06\n",
      "Epoch 934/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8428 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 935/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8428 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 936/960\n",
      "13/13 [==============================] - 125s 10s/step - loss: 1.8428 - accuracy: 0.3800 - val_loss: 1.9599 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 937/960\n",
      "13/13 [==============================] - 134s 10s/step - loss: 1.8428 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 938/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3458 - lr: 1.0000e-06\n",
      "Epoch 939/960\n",
      "13/13 [==============================] - 117s 9s/step - loss: 1.8428 - accuracy: 0.3800 - val_loss: 1.9599 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 940/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8428 - accuracy: 0.3798 - val_loss: 1.9600 - val_accuracy: 0.3449 - lr: 1.0000e-06\n",
      "Epoch 941/960\n",
      "13/13 [==============================] - 131s 10s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3458 - lr: 1.0000e-06\n",
      "Epoch 942/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8428 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 943/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8428 - accuracy: 0.3800 - val_loss: 1.9599 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 944/960\n",
      "13/13 [==============================] - 147s 11s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 945/960\n",
      "13/13 [==============================] - 132s 10s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 946/960\n",
      "13/13 [==============================] - 142s 11s/step - loss: 1.8428 - accuracy: 0.3800 - val_loss: 1.9599 - val_accuracy: 0.3458 - lr: 1.0000e-06\n",
      "Epoch 947/960\n",
      "13/13 [==============================] - 129s 10s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 948/960\n",
      "13/13 [==============================] - 120s 9s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 949/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8428 - accuracy: 0.3799 - val_loss: 1.9599 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 950/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8427 - accuracy: 0.3800 - val_loss: 1.9598 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 951/960\n",
      "13/13 [==============================] - 114s 9s/step - loss: 1.8427 - accuracy: 0.3800 - val_loss: 1.9598 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 952/960\n",
      "13/13 [==============================] - 144s 11s/step - loss: 1.8427 - accuracy: 0.3798 - val_loss: 1.9599 - val_accuracy: 0.3454 - lr: 1.0000e-06\n",
      "Epoch 953/960\n",
      "13/13 [==============================] - 143s 11s/step - loss: 1.8427 - accuracy: 0.3800 - val_loss: 1.9598 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 954/960\n",
      "13/13 [==============================] - 141s 11s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3456 - lr: 1.0000e-06\n",
      "Epoch 955/960\n",
      "13/13 [==============================] - 119s 9s/step - loss: 1.8427 - accuracy: 0.3800 - val_loss: 1.9598 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 956/960\n",
      "13/13 [==============================] - 160s 13s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 957/960\n",
      "13/13 [==============================] - 118s 9s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3457 - lr: 1.0000e-06\n",
      "Epoch 958/960\n",
      "13/13 [==============================] - 128s 10s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3455 - lr: 1.0000e-06\n",
      "Epoch 959/960\n",
      "13/13 [==============================] - 149s 12s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3453 - lr: 1.0000e-06\n",
      "Epoch 960/960\n",
      "13/13 [==============================] - 145s 11s/step - loss: 1.8427 - accuracy: 0.3799 - val_loss: 1.9598 - val_accuracy: 0.3454 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253c9ee5940>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if resume_training:\n",
    "    model = load_model(model_path)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit(\n",
    "    x=training_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=nb_epoch,  # Specify the number of epochs as needed\n",
    "    callbacks = callbacks\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with our trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(r\"C:\\Users\\yaeld\\Desktop\\Coding-Projects\\Prediction-Challenge\\Data\\y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>eqt_code_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160800.00000</td>\n",
       "      <td>160800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80399.50000</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46419.10598</td>\n",
       "      <td>6.922208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40199.75000</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80399.50000</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>120599.25000</td>\n",
       "      <td>17.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>160799.00000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             obs_id   eqt_code_cat\n",
       "count  160800.00000  160800.000000\n",
       "mean    80399.50000      11.500000\n",
       "std     46419.10598       6.922208\n",
       "min         0.00000       0.000000\n",
       "25%     40199.75000       5.750000\n",
       "50%     80399.50000      11.500000\n",
       "75%    120599.25000      17.250000\n",
       "max    160799.00000      23.000000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "20\n",
      "Top 3 predicted labels : [20 21  3]\n",
      "with following Top 3 values: [0.48542622 0.19780622 0.12540379]\n",
      "True Label 21\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0\n",
      "Top 3 predicted labels : [ 0 16  9]\n",
      "with following Top 3 values: [0.59157586 0.17859574 0.1512707 ]\n",
      "True Label 0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "20\n",
      "Top 3 predicted labels : [20 21  3]\n",
      "with following Top 3 values: [0.51727337 0.20434642 0.11373307]\n",
      "True Label 20\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "6\n",
      "Top 3 predicted labels : [ 6  1 14]\n",
      "with following Top 3 values: [0.48318508 0.25440148 0.24987142]\n",
      "True Label 14\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "20\n",
      "Top 3 predicted labels : [20 21  3]\n",
      "with following Top 3 values: [0.34941864 0.23039033 0.16028647]\n",
      "True Label 21\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "5\n",
      "Top 3 predicted labels : [ 5 15  7]\n",
      "with following Top 3 values: [0.41474846 0.27974904 0.10711259]\n",
      "True Label 15\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "21\n",
      "Top 3 predicted labels : [21 22 20]\n",
      "with following Top 3 values: [0.30986473 0.25158417 0.14179005]\n",
      "True Label 20\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "8\n",
      "Top 3 predicted labels : [ 8  2 23]\n",
      "with following Top 3 values: [0.44535515 0.19047794 0.11856452]\n",
      "True Label 14\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "17\n",
      "Top 3 predicted labels : [17  9  0]\n",
      "with following Top 3 values: [0.43605205 0.18981862 0.11196895]\n",
      "True Label 17\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "9\n",
      "Top 3 predicted labels : [ 9  0 17]\n",
      "with following Top 3 values: [0.5887981  0.15433618 0.08729243]\n",
      "True Label 9\n"
     ]
    }
   ],
   "source": [
    "from random import  randint\n",
    "sequence = [randint(0,20000) for j in range(10)]\n",
    "\n",
    "#loading a sequence \n",
    "\n",
    "for i in sequence:\n",
    "        \n",
    "    A = np.load(x_path_npy,mmap_mode='r')[i] #this is a 100x15 sequence\n",
    "    A = np.expand_dims(A, axis=0)  # Adding batch dimension\n",
    "    A.shape\n",
    "    label = np.load(y_path_npy,mmap_mode='r')[i]\n",
    "\n",
    "    predicted = model.predict(A)\n",
    "    \n",
    "    res = predicted[0].argmax()\n",
    "    print(res)\n",
    "\n",
    "    top_3_indices = predicted[0].argsort()[-3:][::-1]\n",
    "\n",
    "    # Get the top 3 values\n",
    "    top_3_values = predicted[0][top_3_indices]\n",
    "\n",
    "    print(\"Top 3 predicted labels :\", top_3_indices)\n",
    "    print(\"with following Top 3 values:\", top_3_values)\n",
    "\n",
    "    #print(f\"Label predicted\", predicted[0].argmax())\n",
    "    print(f\"True Label\",label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a prediction submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_path = \"../Data/X_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(X_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>order_id</th>\n",
       "      <th>action</th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>trade</th>\n",
       "      <th>flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>511</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>511</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>511</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>511</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>511</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  venue  order_id action side  price  bid   ask  bid_size  ask_size  \\\n",
       "0       0      4         0      A    A   0.15  0.0  0.15       511       100   \n",
       "1       0      2         1      D    A   0.16  0.0  0.15       511       100   \n",
       "2       0      4         2      D    A   1.63  0.0  0.15       511       100   \n",
       "3       0      4         3      A    A   1.62  0.0  0.15       511       100   \n",
       "4       0      2         4      A    A   0.15  0.0  0.15       511       200   \n",
       "\n",
       "   trade  flux  \n",
       "0  False   100  \n",
       "1  False  -100  \n",
       "2  False  -100  \n",
       "3  False   100  \n",
       "4  False   100  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from npy_append_array import NpyAppendArray  # Ensure this is correctly installed\n",
    "import logging\n",
    "\n",
    "def process_test_data_chunked(x_test_path, output_prefix, chunk_size=10_000, seq_len=100):\n",
    "    \"\"\"\n",
    "    Process data chunk by chunk and save the results incrementally.\n",
    "\n",
    "    Args:\n",
    "    - x_test_path: Path to the X_test CSV file.\n",
    "    - output_prefix: Prefix for the output files.\n",
    "    - chunk_size: Number of rows to process in each chunk.\n",
    "    - seq_len: Length of each sequence for LSTM.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(filename=\"process_log.log\", level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "    logging.info(\"Starting the chunked processing.\")\n",
    "\n",
    "    # Determine total rows and chunks\n",
    "    total_rows = sum(1 for _ in open(x_test_path)) - 1  # Get total rows excluding header\n",
    "    num_chunks = (total_rows + chunk_size - 1) // chunk_size  # Calculate total chunks\n",
    "\n",
    "    # Output file\n",
    "    X_test_npy_name = f\"../Data/{output_prefix}_X_test.npy\"\n",
    "\n",
    "    try:\n",
    "        # Process in chunks\n",
    "        with NpyAppendArray(X_test_npy_name, delete_if_exists=True) as npaa:\n",
    "            for i, chunk in enumerate(tqdm(pd.read_csv(x_test_path, chunksize=chunk_size), desc=\"Processing Chunks\", total=num_chunks)):\n",
    "                try:\n",
    "                    logging.info(f\"Processing chunk {i + 1} of {num_chunks}.\")\n",
    "\n",
    "                    # Apply the transformation functions\n",
    "                    chunk = correct_df(transform_df(encode_df(chunk)))\n",
    "\n",
    "                    # Create LSTM-compatible data for this chunk\n",
    "                    X_data = create_lstm_data(chunk, seq_len)\n",
    "\n",
    "                    # Append to the .npy file\n",
    "                    npaa.append(X_data)\n",
    "\n",
    "                    # Clear memory\n",
    "                    del X_data, chunk\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in chunk {i + 1}: {e}\")\n",
    "                    continue  # Skip to the next chunk\n",
    "\n",
    "        logging.info(f\"Processing completed. Saved as {output_prefix}_X_test.npy\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Critical error during processing: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8160000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = sum(1 for _ in open(X_test_path)) - 1\n",
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8160000, 12)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chunks: 100%|██████████| 816/816 [00:40<00:00, 20.37it/s]\n"
     ]
    }
   ],
   "source": [
    "process_test_data_chunked(X_test_path,\"09-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_path = fr\"..\\Data\\09-12_X_test.npy\"\n",
    "A = np.load(npy_path,mmap_mode='r') #this is a 100x15 sequence\n",
    "A = np.expand_dims(A, axis=0)  # Adding batch dimension\n",
    "N = len(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81600"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(npy_path):\n",
    "    A = np.load(npy_path,mmap_mode='r') #this is N_obsx100x15 \n",
    "    N = len(A)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        obs_id = i\n",
    "\n",
    "        seq = A[i]\n",
    "        seq = np.expand_dims(seq, axis=0)\n",
    "        predicted = model.predict(seq)\n",
    "        res = predicted[0].argmax()\n",
    "\n",
    "        results.append([obs_id,res])\n",
    "        \n",
    "    df_res = pd.DataFrame(results, columns=['obs_id', 'eqt_code_cat'])\n",
    "\n",
    "    pd.save_csv(df_res,'../Data/submission-09-12.csv',index=False)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'npy_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m create_submission(\u001b[43mnpy_path\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'npy_path' is not defined"
     ]
    }
   ],
   "source": [
    "create_submission(npy_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
